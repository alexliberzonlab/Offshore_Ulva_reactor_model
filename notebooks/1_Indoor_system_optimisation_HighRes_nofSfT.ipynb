{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to find optimal combinations of parameters for minimum model error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.integrate import odeint\n",
    "from scipy import stats\n",
    "from scipy import interpolate\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # to read excel\n",
    "print(f\"pandas version is {pd.__version__}\")\n",
    "import seaborn as sns\n",
    "from array import *\n",
    "import researchpy as rp\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "\n",
    "from local_functions import *\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for optimization (i.e producing random parametric combination)\n",
    "import SALib\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Indoor system\n",
    "#   a. Read data and parameters from excel file\n",
    "\n",
    "xl = pd.ExcelFile('../data/Parameters.xlsx')\n",
    "x2 = pd.ExcelFile('../data/Data.xlsx')\n",
    "\n",
    "# Import parameters into df1\n",
    "df1 = xl.parse('Parameters')\n",
    "\n",
    "# assigmment of parameters to values: \n",
    "for key,val in zip(df1.Parameter,df1.Indoor_value):\n",
    "    exec(key + '=val')\n",
    "    print(key,val)\n",
    "\n",
    "# Import indoor data into df2\n",
    "df2 = x2.parse('Indoor')\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. process data (indoor measurements)\n",
    "\n",
    "    # 1. Convert Time into hours\n",
    "T = []\n",
    "for i in df2['Sample'][:]:\n",
    "    T1 = df2['Timei'][df2['Sample'].values.tolist().index(i)]\n",
    "    T2 = df2['Time'][df2['Sample'].values.tolist().index(i)]\n",
    "    T.append(Time_to_Hours(T1,T2))\n",
    "df2['T'] = T\n",
    "\n",
    "    # 2. Make a temp DF (df2_temp) by filtering the original df - remove 'wierd' results (i.e sporulation) \n",
    "\n",
    "df2_Reduced = df2[(df2.Treatment != 'Acclimation') & (df2.Week <= 3) & (df2.Stage != 'i') & (df2.Sporulated == 'No')&(df2.Comment != 'Exclude')]\n",
    "df2_Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calculate model results for:\n",
    "#   a. Indoor system\n",
    "    # I. Produce an array (\"m/Nint/Next_mod_all\") of all model results (hours 1-504) for each treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized parameters: bounds\n",
    "#'µmax'\n",
    "problem = {\n",
    "    'num_vars': 9,\n",
    "    'names': ['λ20','Nintmax','Nintcrit','Nextlosses','Ks','Vmax','KI','K0','Ka'],\n",
    "    'bounds': [[0.001,0.005],\n",
    "               [4.5,5],\n",
    "               [0.7,3.2],\n",
    "               [0.001,0.02],\n",
    "               [10,30],\n",
    "               [50,250],\n",
    "               [15, 150],\n",
    "               [0.1,3],\n",
    "               [0.01,0.2]]\n",
    "}\n",
    "\n",
    "print(problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of examined values per parameter - 100\n",
    "param_values = saltelli.sample(problem, 250)\n",
    "print(param_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model simulations with different parameteric combinations\n",
    "\n",
    "\n",
    "Y1 = np.zeros([param_values.shape[0]])\n",
    "Y2 = np.zeros([param_values.shape[0]])\n",
    "\n",
    "evaluate_model1 = []\n",
    "evaluate_model2 = []\n",
    "\n",
    "Temp = 22\n",
    "S = 39 # fix salinity function and S=40\n",
    "\n",
    "Treatments = ['1000/1/168','500/2/168','500/3/168','2000/1/168','200/5/168']\n",
    "Nint0All = ['2.12','2.13','2.32','2.05','1.3']\n",
    "\n",
    "r = 0\n",
    "\n",
    "miu = 0.03\n",
    "for p, X in enumerate(param_values):\n",
    "   \n",
    "    #miu = X[0]\n",
    "    lossess20 = X[0]\n",
    "    Nintmax = X[1]\n",
    "    Nintcrit = X[2]\n",
    "    dNextoutdt = X[3]\n",
    "    Ks = X[4]\n",
    "    Vmax = X[5]\n",
    "    KI = X[6]\n",
    "    K0 = X[7]\n",
    "    Ka = X[8]\n",
    "\n",
    "\n",
    "    \n",
    "    TModAll = [] # Each sub-array has the time steps of a specific treatment (periods)\n",
    "    mExpAllTimes,NintExpAllTimes,NextExpAllTimes = [],[],[]\n",
    "    mModAll,NintModAll,NextModAll = [],[],[]\n",
    "\n",
    "    for i in Treatments:\n",
    "        df2_ReducedTemp = df2_Reduced[(df2_Reduced.Exp != 1)&(df2_Reduced.Exp != 2)&(df2_Reduced.Exp != 5)]\n",
    "        df2Temp = df2_ReducedTemp[(df2_ReducedTemp.Treatment == i)]\n",
    "        #mTemp = df2Temp[(np.isnan(df2Temp.DW) != True)]['DW']\n",
    "        #mTimeTemp = df2Temp[(np.isnan(df2Temp.DW) != True)]['T']\n",
    "        #NintTemp = df2Temp[(np.isnan(df2Temp.N) != True)]['N']\n",
    "        #NintTimeTemp = df2Temp[(np.isnan(df2Temp.N) != True)]['T']\n",
    "        #NextTemp = df2Temp[(np.isnan(df2Temp.NH4) != True)]['NH4']\n",
    "        #NextTimeTemp = df2Temp[(np.isnan(df2Temp.NH4) != True)]['T']\n",
    "        mTemp = df2Temp[(~np.isnan(df2Temp.DW))]['DW']\n",
    "        mTimeTemp = df2Temp[(~np.isnan(df2Temp.DW))]['T']\n",
    "        NintTemp = df2Temp[(~np.isnan(df2Temp.N))]['N']\n",
    "        NintTimeTemp = df2Temp[(~np.isnan(df2Temp.N))]['T']\n",
    "        NextTemp = df2Temp[(~np.isnan(df2Temp.NH4))]['NH4']\n",
    "        NextTimeTemp = df2Temp[(~np.isnan(df2Temp.NH4))]['T']\n",
    "\n",
    "        Tr = []\n",
    "        Tr = i.split('/')\n",
    "        Tr = [float(i) for i in Tr]\n",
    "        Amplitude = Tr[0]\n",
    "        Period = float(7/Tr[1]) # Period is in hours\n",
    "        Duration = Tr[2]/24\n",
    "\n",
    "        NEXT, NINT, M, TT = [],[],[],[]\n",
    "\n",
    "        n_days = Duration*3\n",
    "        count_periods = 0\n",
    "\n",
    "        # hour = 0 is 1pm\n",
    "        # in the indoor settings we have to solve for shorter periods, \n",
    "        # at the beginning of the Treatment we reset Nint, Next, m\n",
    "        # at the beginning of each Period we set Next to the last Amplitude, \n",
    "        # m0 to the end of previous solution of ode()\n",
    "\n",
    "        # Let's prepare the IO(t) function that will be supplied to odeint \n",
    "        # instead of a scalar. \n",
    "\n",
    "        all_treatment_hours = np.arange(0,n_days*24,dtype=np.int)\n",
    "\n",
    "        # 8pm on the first day is zero crossing of this one 8pm - 10m = 7 hours\n",
    "        offtimes = all_treatment_hours[np.mod(all_treatment_hours - 7,24) == 0]\n",
    "        offtimes = np.r_[offtimes,all_treatment_hours[-1]+1] # last hour would be whatever\n",
    "\n",
    "        # 6am on the next day is zero crossing of this one, 6am - 8pm is 10 hours\n",
    "        ontimes = all_treatment_hours[np.mod(all_treatment_hours - 7 + 10,24) == 0]\n",
    "        # and the iniital hour as we always start at 1pm, during ontime\n",
    "        ontimes = np.r_[np.int(0),ontimes]\n",
    "\n",
    "        # prepare the duty cycle\n",
    "        I0set = np.zeros_like(all_treatment_hours)\n",
    "        for s,e in zip(ontimes,offtimes):\n",
    "            I0set[s:e] = 80\n",
    "\n",
    "        # if you want to replace it by a \"constant\" I0 then replace the lines above with\n",
    "        # the following line and then it will also give you a constant solution you had before\n",
    "\n",
    "        # I0set = np.ones_like(all_treatment_hours)*80\n",
    "\n",
    "\n",
    "        I0 = interpolate.interp1d(all_treatment_hours, I0set, bounds_error=False, fill_value=\"extrapolate\")\n",
    "\n",
    "        for hour in np.arange(0,n_days*24,round(Period*24,0)):\n",
    "            if hour == 0:\n",
    "                Nint_0 = Nint0All[Treatments.index(i)]\n",
    "                m_0 = m0\n",
    "                Next_0 = Amplitude\n",
    "\n",
    "            if hour > 0 and np.mod(hour,round(Period*24,0)) == 0:\n",
    "                count_periods = count_periods + 1\n",
    "\n",
    "                if count_periods == Tr[1]:\n",
    "                    # reset everything, except Nint\n",
    "                    Nint_0 = NINT[-1][-1]\n",
    "                    Next_0 = Amplitude\n",
    "                    m_0 = m0\n",
    "                    count_periods = 0\n",
    "                else:\n",
    "                    # period passed, not Duration\n",
    "                    # add amplitude, keep going \n",
    "                    Next_0 = NEXT[-1][-1] + Amplitude\n",
    "                    Nint_0 = NINT[-1][-1]\n",
    "                    m_0 = M[-1][-1]\n",
    "\n",
    "\n",
    "            # Here we want to send odeint the times of the light sub-period or \n",
    "            # darkness sub-period\n",
    "\n",
    "            x0 = [Next_0,Nint_0,m_0]\n",
    "            # t = np.linspace(hour,hour+Period*24) # every time we solve ODE for 24 hours * Period\n",
    "            t = np.arange(hour, hour+Period*24) # can also ask for report on round hours\n",
    "\n",
    "            x = odeint(controlled_N_constST,x0,t,args=(Nintmax,Nintmin,Vmax,Ks,dNextoutdt,dNextindt,miu,dmoutdt,Nintcrit,Z,KI,K0,Ka,\n",
    "                                                   losses20,teta,umol_to_percent_DW,I0,Temp),printmessg=0,hmax=.1)\n",
    "\n",
    "            NEXT.append(x[: , 0])\n",
    "            NINT.append(x[: , 1])\n",
    "            M.append(x[: , 2])\n",
    "            TT.append(t)\n",
    "\n",
    "            t_model = np.hstack(TT)\n",
    "            Next_model = np.hstack(NEXT)\n",
    "            Nint_model = np.hstack(NINT)\n",
    "            m_model = np.hstack(M)\n",
    "\n",
    "        TModAll.append(TT)\n",
    "        mExpAllTimes.append(mTimeTemp)\n",
    "        NintExpAllTimes.append(NintTimeTemp)\n",
    "        NextExpAllTimes.append(NextTimeTemp)\n",
    "\n",
    "        mModAll.append(m_model)\n",
    "        NintModAll.append(Nint_model)\n",
    "        NextModAll.append(Next_model)\n",
    "        \n",
    "    # Adjusts measurment time to model durations - so that maximum biomass measurements are compared to maximum biomass\n",
    "    # predictions and not to the initial stocking density (m0)\n",
    "\n",
    "    TModTemp = []\n",
    "    TModAllOrg = []\n",
    "    mModReducedAll, NintModReducedAll, NextModReducedAll = [],[],[]\n",
    "    for j in range(len(TModAll)): # loops over 5 treatments\n",
    "        #print(j)\n",
    "        for k in range(len(TModAll[j])): # Loops over periods in each treatment\n",
    "            Ttemp = TModAll[j][k]\n",
    "            for l in Ttemp: #The model ends at 504 hours, but some measurement reach also 50 hours. This sets a 504 hour limit\n",
    "                if l > 504:\n",
    "                    l = 504\n",
    "                TModTemp.append(l)\n",
    "        TModAllOrg.append(TModTemp)\n",
    "        TModTemp = []\n",
    "\n",
    "    for j in range(len(TModAll)):\n",
    "        gm = interpolate.interp1d(TModAllOrg[j], mModAll[j],kind = 'linear')\n",
    "        mModReduced = []\n",
    "        for k in mExpAllTimes[j]:\n",
    "            #print(mExpAllTimes[i])\n",
    "            if k >= 168 and k < 180:\n",
    "                k = 167.9\n",
    "            elif k >= 336 and k < 345:\n",
    "                k = 335.9\n",
    "            elif k > 504:\n",
    "                k = 504\n",
    "            #print(j)\n",
    "            mModReduced.append(gm(k-1))\n",
    "\n",
    "        mModReducedAll.append(mModReduced)\n",
    "        gNint = interpolate.interp1d(TModAllOrg[j], NintModAll[j],kind = 'linear')\n",
    "        NintModReduced = []\n",
    "        for k in NintExpAllTimes[j]:\n",
    "            if k >= 168 and k < 180:\n",
    "                k = 167.9\n",
    "            if k >= 336 and k < 345:\n",
    "                k = 335.9\n",
    "            if k > 504:\n",
    "                k = 504\n",
    "            NintModReduced.append(gNint(k-1))\n",
    "        NintModReducedAll.append(NintModReduced)\n",
    "        gNext = interpolate.interp1d(TModAllOrg[j], NextModAll[j],kind = 'linear')    \n",
    "        NextModReduced = []\n",
    "        for k in NextExpAllTimes[j]:\n",
    "            if k >= 168 and k < 180:\n",
    "                k = 167.9\n",
    "            if k >= 336 and k < 345:\n",
    "                k = 335.9\n",
    "            if k > 504:\n",
    "                k = 504\n",
    "            NextModReduced.append(gNext(k-1))\n",
    "        NextModReducedAll.append(NextModReduced)\n",
    "\n",
    "    \n",
    "    # calculate errors\n",
    "    mSRE_All,NintSRE_All,NextSRE_All = [],[],[]\n",
    "    for j in range(len(Treatments)):\n",
    "        mSRE,NintSRE,NextSRE = [],[],[]\n",
    "        RMSREmAll,RMSRENintAll = [],[]\n",
    "        \n",
    "        df2m = df2_ReducedTemp[(np.isnan(df2_ReducedTemp.DW) != True)&(df2_ReducedTemp.Treatment == Treatments[j])]\n",
    "        #print('Treatment: ' + str(Treatments[j]) + '\\n\\nm\\n')\n",
    "        #print('Number of samples: ' + str(len(df2m.Sample)) + '\\n')\n",
    "        l = 0\n",
    "        for k in df2m.Sample:\n",
    "            mexp = df2m.DW\n",
    "            #print(j)\n",
    "            #print(len(mModReducedAll))\n",
    "            mmod = mModReducedAll[j]\n",
    "            mSRE.append(((mexp.iloc[l]-mmod[l])/mmod[l])**2)\n",
    "            mSRE_All.append(((mexp.iloc[l]-mmod[l])/mmod[l])**2)\n",
    "            #print('Sample #' + str(math.floor(float(k))))\n",
    "            #print('Measured biomass: ' + str(round(mexp.iloc[l],3)))\n",
    "            #print('Modeled biomass: ' + str(round(float(mmod[l]),3)) + '\\n')\n",
    "            l = l + 1\n",
    "            RMSREm = round((np.mean(mSRE))**0.5,3)\n",
    "            \n",
    "        #print('The RMSRE of m in treamtment ' + str(Treatments[j]) + ' is: ' + str(RMSREm) + '\\n')\n",
    "\n",
    "\n",
    "        df2Nint = df2_ReducedTemp[(np.isnan(df2_ReducedTemp.N) != True)][(df2_ReducedTemp.Treatment == Treatments[j])]\n",
    "        #print('\\nNint\\n')\n",
    "        #print('Number of samples: ' + str(len(df2Nint.Sample)) + '\\n')\n",
    "        l = 0\n",
    "        for k in df2Nint.Sample:\n",
    "            Nintexp = df2Nint.N\n",
    "            Nintmod = NintModReducedAll[j]\n",
    "            NintSRE.append(((Nintexp.iloc[l]-Nintmod[l])/Nintmod[l])**2)\n",
    "            NintSRE_All.append(((Nintexp.iloc[l]-Nintmod[l])/Nintmod[l])**2)\n",
    "            #print('Sample #' + str(math.floor(float(k))))\n",
    "            #print('Measured Nint: ' + str(round(float(Nintexp.iloc[l]),3)))     \n",
    "            #print('Modeled Nint: ' + str(round(float(Nintmod[l]),3)) + '\\n')        \n",
    "            l = l + 1\n",
    "            RMSRENint = round((np.mean(NintSRE))**0.5,3)\n",
    "            \n",
    "        #print('\\nThe RMSRE of Nint in treamtment ' + str(Treatments[j]) + ' is: ' + str(RMSRENint) + '\\n')\n",
    "\n",
    "        df2Next = df2_ReducedTemp[(np.isnan(df2_ReducedTemp.NH4) != True)][(df2_ReducedTemp.Treatment == Treatments[j])]\n",
    "        #print('\\nNext\\n')\n",
    "        #print('Number of samples: ' + str(len(df2Next.Sample)) + '\\n')\n",
    "        l = 0\n",
    "        for k in df2Next.Sample:\n",
    "            Nextexp = df2Next.NH4\n",
    "            if Nextexp.iloc[l] < 0:\n",
    "                Nextexp.iloc[l] = 0\n",
    "            Nextmod = NextModReducedAll[j]\n",
    "            NextSRE.append(((Nextexp.iloc[l]-Nextmod[l])/Nextmod[l])**2)\n",
    "            #print('Sample #' + str(math.floor(float(k))))\n",
    "            #print('Measured Next: ' + str(round(float(Nextexp.iloc[l]),3)))     \n",
    "            #print('Modeled Next: ' + str(round(float(Nextmod[l]),3)) + '\\n')        \n",
    "            l = l + 1\n",
    "            RMSRENext = round((np.mean(NextSRE))**0.5,3)\n",
    "            NextSRE_All.append(NextSRE)\n",
    "        #print('\\nThe RMSRE of Next in treamtment ' + str(Treatments[j]) + ' is: ' + str(RMSRENext) + '\\n')\n",
    "    #print('End of treatment ' + str(Treatments[j]) + '\\n')\n",
    "    \n",
    "\n",
    "    #mSRE_AllTemp = []\n",
    "    #for i in range(len(mSRE_All)):\n",
    "    #    for j in range(len(mSRE_All[i])):\n",
    "    #        mSRE_AllTemp.append(mSRE_All[i][j])\n",
    "    RMSREm = round((np.mean(mSRE_All))**0.5,3)\n",
    "\n",
    "    #NintSRE_AllTemp = []\n",
    "    #for i in range(len(NintSRE_All)):\n",
    "    #    for j in range(len(NintSRE_All[i])):\n",
    "    #        NintSRE_AllTemp.append(NintSRE_All[i][j])\n",
    "    RMSRENint = round((np.mean(NintSRE_All))**0.5,3)\n",
    "    \n",
    "    evaluate_model1.append(RMSREm)\n",
    "    evaluate_model2.append(RMSRENint)\n",
    "    #evaluate_model3.append(RMSRENext)\n",
    "\n",
    "    Y1[p] = round(evaluate_model1[-1],3)\n",
    "    Y2[p] = round(evaluate_model2[-1],3)\n",
    "    print(r)\n",
    "    r = r+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mSRE_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(Y1),min(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(Y1))\n",
    "print(np.mean(Y1))\n",
    "print(np.std(Y1))\n",
    "print(np.median(Y1))\n",
    "print(max(Y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si1 = sobol.analyze(problem, Y1,print_to_console=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(Y2))\n",
    "print(np.mean(Y2))\n",
    "print(np.std(Y2))\n",
    "print(np.median(Y2))\n",
    "print(max(Y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si2 = sobol.analyze(problem, Y2,print_to_console=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ST2 = plt.subplots(1,1,sharex=True,figsize=(4,5))\n",
    "#ST2.plot(Si3['ST'],problem['names'],'s',markersize=5,color='dimgray')\n",
    "ST2.plot(Si2['ST'],problem['names'],'*',markersize=7,color='dodgerblue')\n",
    "ST2.plot(Si1['ST'],problem['names'],'.',markersize=10,color='black')\n",
    "\n",
    "\n",
    "ST2.set_xlabel('Sensitivity Index',fontsize=14, weight=\"bold\")\n",
    "ST2.set_ylabel('Parameter',fontsize=14, weight=\"bold\")\n",
    "ST2.set_xlim([0, 1])\n",
    "ST2.set_axisbelow(True)\n",
    "ST2.yaxis.grid(color='lightgray', linestyle='dashed')\n",
    "ST2.legend(['Internal N','m'])\n",
    "\n",
    "\n",
    "name = 'Indoor Sensitivity.png' \n",
    "fig.savefig(fname=name, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = param_values.T\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_index = []\n",
    "for i in range(len(Y1)):\n",
    "    if (Y1[i] < 5) & (Y2[i] < 5):\n",
    "        #print(\"parameters of index \" + str(i) + \" give error \" + str(Y[i]) + \"\\n\")\n",
    "        Best_index.append(i)\n",
    "        \n",
    "b = param_values[Best_index].T\n",
    "\n",
    "#print(b)\n",
    "fig,ax0 = plt.subplots(3,3,figsize=(18,21),sharey=True)#,sharex=True)\n",
    "\n",
    "for j in range(len(b)):\n",
    "    ax0.flat[j].plot(b[j],Y1[Best_index],'.',markersize=6,color = 'lightblue')\n",
    "    ax0.flat[j].plot(b[j],Y2[Best_index],'.',markersize=6,color = 'pink')\n",
    "    ax0.flat[j].set_xlabel(str(problem['names'][j]),fontsize=11, weight=\"bold\")\n",
    "    #ax0.flat[j].set_ylabel('RMSRE',fontsize=12, weight=\"bold\")\n",
    "    #ax0.flat[j].set_xlim(problem['bounds'][0])\n",
    "    \n",
    "    # regression line and coefficient for m:\n",
    "    mm, bb = np.polyfit(b[j], Y1[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], mm*b[j] + bb,'.',color = 'blue',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, Y1[Best_index])\n",
    "    model = LinearRegression().fit(x, Y1[Best_index])\n",
    "    r_sq = model.score(x, Y1[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    #ax0.flat[j].legend(['$R^{2}$ = ' + str(round(r_sq,2))])\n",
    "\n",
    "    # regression line and coefficient for Nint:\n",
    "    NN, cc = np.polyfit(b[j], Y2[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], NN*b[j] + cc,'.',color = 'red',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    modelN = LinearRegression()\n",
    "    modelN.fit(x, Y2[Best_index])\n",
    "    modelN = LinearRegression().fit(x, Y2[Best_index])\n",
    "    r_sqN = modelN.score(x, Y2[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    ax0.flat[j].legend([['$R^{2}$ = ' + str(round(r_sq,2))],['$R^{2}$ = ' + str(round(r_sqN,2))]],fontsize = 14,loc = 'upper center')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "name = 'Indoor Error plots.png' \n",
    "    \n",
    "fig.savefig(fname=name, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y3 = Y1+Y2\n",
    "Best_index = []\n",
    "for i in range(len(Y3)):\n",
    "    Best_index.append(i)\n",
    "        \n",
    "b = param_values[Best_index].T\n",
    "\n",
    "#print(b)\n",
    "fig,ax0 = plt.subplots(3,3,figsize=(18,21),sharey=True)#,sharex=True)\n",
    "\n",
    "for j in range(len(b)):\n",
    "    ax0.flat[j].plot(b[j],Y3[Best_index],'.',markersize=6,color = 'lightgreen')\n",
    "    #ax0.flat[j].plot(b[j],Y2[Best_index],'.',markersize=6,color = 'pink')\n",
    "    ax0.flat[j].set_xlabel(str(problem['names'][j]),fontsize=11, weight=\"bold\")\n",
    "    #ax0.flat[j].set_ylabel('RMSRE',fontsize=12, weight=\"bold\")\n",
    "    #ax0.flat[j].set_xlim(problem['bounds'][0])\n",
    "    \n",
    "    # regression line and coefficient:\n",
    "    MN, DD = np.polyfit(b[j], Y3[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], MN*b[j] + DD,'.',color = 'darkgreen',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, Y3[Best_index])\n",
    "    model = LinearRegression().fit(x, Y3[Best_index])\n",
    "    r_sq = model.score(x, Y3[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    #ax0.flat[j].legend(['$R^{2}$ = ' + str(round(r_sq,2))])\n",
    "\n",
    "    ax0.flat[j].legend([['$R^{2}$ = ' + str(round(r_sq,2))]],fontsize = 14,loc = 'upper center')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "name = 'Indoor Combined Error plots.png' \n",
    "    \n",
    "fig.savefig(fname=name, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfP = pd.DataFrame(param_values[0:-1])\n",
    "dfY1 = pd.DataFrame(Y1[0:-1])\n",
    "dfY2 = pd.DataFrame(Y2[0:-1])\n",
    "dfP.to_csv('Indoor_param_values.csv',index=False)\n",
    "dfY1.to_csv('Indoor_Y1.csv',index=False)\n",
    "dfY2.to_csv('Indoor_Y2.csv',index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y5 = pd.read_csv (r'C:\\Users\\meiro\\Desktop\\GitHub\\notebooks\\Indoor_Y1.csv')\n",
    "Y6 = pd.read_csv (r'C:\\Users\\meiro\\Desktop\\GitHub\\notebooks\\Indoor_Y2.csv')\n",
    "P = pd.read_csv (r'C:\\Users\\meiro\\Desktop\\GitHub\\notebooks\\Indoor_param_values.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y5 = Y5.iloc[:,:].values\n",
    "Y6 = Y6.iloc[:,:].values\n",
    "P = P.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_index = []\n",
    "for i in range(len(Y1)):\n",
    "    if (Y1[i] < 0.5) & (Y2[i] < 0.5):\n",
    "        #print(\"parameters of index \" + str(i) + \" give error \" + str(Y[i]) + \"\\n\")\n",
    "        Best_index.append(i)\n",
    "        #.twinx()\n",
    "b = param_values[Best_index].T\n",
    "\n",
    "#print(b)\n",
    "fig,ax0 = plt.subplots(3,3,figsize=(18,21),sharey=True)#,sharex=True)\n",
    "\n",
    "#ax2 = ax0[0].twinx()\n",
    "\n",
    "for j in range(len(b)):\n",
    "    ax0.flat[j].plot(b[j],Y1[Best_index],'.',markersize=6,color = 'lightblue')\n",
    "    ax0.flat[j].plot(b[j],Y2[Best_index],'.',markersize=6,color = 'pink')\n",
    "    ax0.flat[j].set_xlabel(str(problem['names'][j]),fontsize=11, weight=\"bold\")\n",
    "    #ax0.flat[j].set_ylabel('RMSRE',fontsize=12, weight=\"bold\")\n",
    "    #ax0.flat[j].set_xlim(problem['bounds'][0])\n",
    "    \n",
    "    # regression line and coefficient for m:\n",
    "    mm, bb = np.polyfit(b[j], Y1[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], mm*b[j] + bb,'.',color = 'blue',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, Y1[Best_index])\n",
    "    model = LinearRegression().fit(x, Y1[Best_index])\n",
    "    r_sq = model.score(x, Y1[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    #ax0.flat[j].legend(['$R^{2}$ = ' + str(round(r_sq,2))])\n",
    "\n",
    "    # regression line and coefficient for Nint:\n",
    "    NN, cc = np.polyfit(b[j], Y2[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], NN*b[j] + cc,'.',color = 'red',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    modelN = LinearRegression()\n",
    "    modelN.fit(x, Y2[Best_index])\n",
    "    modelN = LinearRegression().fit(x, Y2[Best_index])\n",
    "    r_sqN = modelN.score(x, Y2[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    ax0.flat[j].legend([['$R^{2}$ = ' + str(round(r_sq,2))],['$R^{2}$ = ' + str(round(r_sqN,2))]],fontsize = 14,loc = 'upper center')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_index = []\n",
    "for i in range(len(Y1)):\n",
    "    if (Y1[i] < 0.3) & (Y2[i] < 0.3):\n",
    "        #print(\"parameters of index \" + str(i) + \" give error \" + str(Y[i]) + \"\\n\")\n",
    "        Best_index.append(i)\n",
    "        \n",
    "b = param_values[Best_index].T\n",
    "\n",
    "#print(b)\n",
    "fig,ax0 = plt.subplots(3,3,figsize=(18,21),sharey=True)#,sharex=True)\n",
    "\n",
    "for j in range(len(b)):\n",
    "    ax0.flat[j].plot(b[j],Y1[Best_index],'.',markersize=6,color = 'lightblue')\n",
    "    ax0.flat[j].plot(b[j],Y2[Best_index],'.',markersize=6,color = 'pink')\n",
    "    ax0.flat[j].set_xlabel(str(problem['names'][j]),fontsize=11, weight=\"bold\")\n",
    "    #ax0.flat[j].set_ylabel('RMSRE',fontsize=12, weight=\"bold\")\n",
    "    #ax0.flat[j].set_xlim(problem['bounds'][0])\n",
    "    \n",
    "    # regression line and coefficient for m:\n",
    "    mm, bb = np.polyfit(b[j], Y1[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], mm*b[j] + bb,'.',color = 'blue',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, Y1[Best_index])\n",
    "    model = LinearRegression().fit(x, Y1[Best_index])\n",
    "    r_sq = model.score(x, Y1[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    #ax0.flat[j].legend(['$R^{2}$ = ' + str(round(r_sq,2))])\n",
    "\n",
    "    # regression line and coefficient for Nint:\n",
    "    NN, cc = np.polyfit(b[j], Y2[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], NN*b[j] + cc,'.',color = 'red',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    modelN = LinearRegression()\n",
    "    modelN.fit(x, Y2[Best_index])\n",
    "    modelN = LinearRegression().fit(x, Y2[Best_index])\n",
    "    r_sqN = modelN.score(x, Y2[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    ax0.flat[j].legend([['$R^{2}$ = ' + str(round(r_sq,2))],['$R^{2}$ = ' + str(round(r_sqN,2))]],fontsize = 14,loc = 'upper center')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y3 = Y1 + Y2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "Best_index = []\n",
    "for i in range(len(Y1)):\n",
    "    if (Y1[i] < 5) & (Y2[i] < 5):\n",
    "        Best_index.append(i)\n",
    "        \n",
    "b = param_values[Best_index].T\n",
    "\n",
    "fig,ax0 = plt.subplots(3,3,figsize=(18,21),sharey=True)#,sharex=True)\n",
    "\n",
    "for j in range(len(b)):\n",
    "    ax0.flat[j].plot(b[j],Y1[Best_index],'.',markersize=4,color = 'lightblue')\n",
    "    ax0.flat[j].plot(b[j],Y2[Best_index],'.',markersize=4,color = 'pink')\n",
    "    ax0.flat[j].plot(b[j],Y3[Best_index],'.',markersize=6,color = 'lightgreen')\n",
    "    ax0.flat[j].set_xlabel(str(problem['names'][j]),fontsize=11, weight=\"bold\")\n",
    "    \n",
    "    \n",
    "    # regression line and coefficient:\n",
    "    mm, bb = np.polyfit(b[j], Y1[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], mm*b[j] + bb,'.',color = 'blue',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, Y1[Best_index])\n",
    "    model = LinearRegression().fit(x, Y1[Best_index])\n",
    "    r_sq = model.score(x, Y1[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    #ax0.flat[j].legend([['$R^{2}$ = ' + str(round(r_sq,2))],['$R^{2}$ = ' + str(round(r_sqN,2))]])\n",
    "\n",
    "    # regression line and coefficient for Nint:\n",
    "    NN, cc = np.polyfit(b[j], Y2[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], NN*b[j] + cc,'.',color = 'red',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    modelN = LinearRegression()\n",
    "    modelN.fit(x, Y2[Best_index])\n",
    "    modelN = LinearRegression().fit(x, Y2[Best_index])\n",
    "    r_sqN = modelN.score(x, Y2[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    \n",
    "    # Combined (Y3)\n",
    "    \n",
    "    #ax0.flat[j].plot(b[j],Y2[Best_index],'.',markersize=6,color = 'pink')\n",
    "    #ax0.flat[j].set_xlabel(str(problem['names'][j]),fontsize=11, weight=\"bold\")\n",
    "    #ax0.flat[j].set_ylabel('RMSRE',fontsize=12, weight=\"bold\")\n",
    "    #ax0.flat[j].set_xlim(problem['bounds'][0])\n",
    "    \n",
    "    # regression line and coefficient:\n",
    "    MN, DD = np.polyfit(b[j], Y3[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], MN*b[j] + DD,'.',color = 'darkgreen',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, Y3[Best_index])\n",
    "    model = LinearRegression().fit(x, Y3[Best_index])\n",
    "    r_sqC = model.score(x, Y3[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    #ax0.flat[j].legend(['$R^{2}$ = ' + str(round(r_sq,2))])\n",
    "\n",
    "    #ax0.flat[j].legend([['$R^{2}$ = ' + str(round(r_sq,2))]],fontsize = 14,loc = 'upper center')\n",
    "    \n",
    "    ax0.flat[j].legend([['$R^{2}$ = ' + str(round(r_sq,2))],['$R^{2}$ = ' + str(round(r_sqN,2))],['$R^{2}$ = ' + str(round(r_sqC,2))]],fontsize = 14,loc = 'upper left',markerscale = 2.5)\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "name = 'Indoor Full Error plots.png' \n",
    "    \n",
    "fig.savefig(fname=name, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y3 = Y1 + Y2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "Best_index = []\n",
    "for i in range(len(Y1)):\n",
    "    if (Y1[i] < 0.5) & (Y2[i] < 0.5):\n",
    "        Best_index.append(i)\n",
    "        \n",
    "b = param_values[Best_index].T\n",
    "\n",
    "fig,ax0 = plt.subplots(3,3,figsize=(18,21),sharey=True)#,sharex=True)\n",
    "\n",
    "for j in range(len(b)):\n",
    "    ax0.flat[j].plot(b[j],Y1[Best_index],'.',markersize=4,color = 'dodgerblue')\n",
    "    ax0.flat[j].plot(b[j],Y2[Best_index],'.',markersize=4,color = 'pink')\n",
    "    ax0.flat[j].plot(b[j],Y3[Best_index],'.',markersize=6,color = 'lightgreen')\n",
    "    ax0.flat[j].set_xlabel(str(problem['names'][j]),fontsize=11, weight=\"bold\")\n",
    "    \n",
    "    \n",
    "    # regression line and coefficient:\n",
    "    mm, bb = np.polyfit(b[j], Y1[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], mm*b[j] + bb,'.',color = 'blue',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, Y1[Best_index])\n",
    "    model = LinearRegression().fit(x, Y1[Best_index])\n",
    "    r_sq = model.score(x, Y1[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    #ax0.flat[j].legend([['$R^{2}$ = ' + str(round(r_sq,2))],['$R^{2}$ = ' + str(round(r_sqN,2))]])\n",
    "\n",
    "    # regression line and coefficient for Nint:\n",
    "    NN, cc = np.polyfit(b[j], Y2[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], NN*b[j] + cc,'.',color = 'red',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    modelN = LinearRegression()\n",
    "    modelN.fit(x, Y2[Best_index])\n",
    "    modelN = LinearRegression().fit(x, Y2[Best_index])\n",
    "    r_sqN = modelN.score(x, Y2[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    \n",
    "    # Combined (Y3)\n",
    "    \n",
    "    #ax0.flat[j].plot(b[j],Y2[Best_index],'.',markersize=6,color = 'pink')\n",
    "    #ax0.flat[j].set_xlabel(str(problem['names'][j]),fontsize=11, weight=\"bold\")\n",
    "    #ax0.flat[j].set_ylabel('RMSRE',fontsize=12, weight=\"bold\")\n",
    "    #ax0.flat[j].set_xlim(problem['bounds'][0])\n",
    "    \n",
    "    # regression line and coefficient:\n",
    "    MN, DD = np.polyfit(b[j], Y3[Best_index], 1)\n",
    "    ax0.flat[j].plot(b[j], MN*b[j] + DD,'.',color = 'darkgreen',markersize=4)\n",
    "    x = np.array(b[j]).reshape((-1, 1))\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, Y3[Best_index])\n",
    "    model = LinearRegression().fit(x, Y3[Best_index])\n",
    "    r_sqC = model.score(x, Y3[Best_index])\n",
    "    #print('KI coefficient of determination:', r_sq)\n",
    "    #ax0.flat[j].legend(['$R^{2}$ = ' + str(round(r_sq,2))])\n",
    "\n",
    "    #ax0.flat[j].legend([['$R^{2}$ = ' + str(round(r_sq,2))]],fontsize = 14,loc = 'upper center')\n",
    "    \n",
    "    ax0.flat[j].legend([['$R^{2}$ = ' + str(round(r_sq,2))],['$R^{2}$ = ' + str(round(r_sqN,2))],['$R^{2}$ = ' + str(round(r_sqC,2))]],fontsize = 14,loc = 'upper left',markerscale = 2.5)\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "name = 'Indoor Error plots reduced.png' \n",
    "    \n",
    "fig.savefig(fname=name, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y3 = Y1 + Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parametric combinations\n",
    "\n",
    "Y1.tolist().index(min(Y1)),Y2.tolist().index(min(Y2))\n",
    "param_values[Y1.tolist().index(min(Y1))],param_values[Y2.tolist().index(min(Y2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minerrorm = min(Y1)\n",
    "minerrorN = min(Y2)\n",
    "minsumerrors = min(Y3)\n",
    "\n",
    "merror_best = Y1[Y3.tolist().index(min(Y3))]\n",
    "Nerror_best = Y2[Y3.tolist().index(min(Y3))]\n",
    "\n",
    "#indminerrorm = Y1.tolist().index(min(Y3))\n",
    "#indminerrorN = Y2.tolist().index(min(Y3))\n",
    "BestParam_m = param_values[Y1.tolist().index(min(Y1))]\n",
    "BestParam_N = param_values[Y2.tolist().index(min(Y2))]\n",
    "BestParam = param_values[Y3.tolist().index(min(Y3))]\n",
    "\n",
    "print('Minimum error for m: ' + str(minerrorm))\n",
    "print('Minimum error for Nint: ' + str(minerrorN) + '\\n')\n",
    "print('Minimum sum of errors: ' + str(minsumerrors) + '\\n')\n",
    "print('Best error for m: ' + str(merror_best))\n",
    "print('Best error for N: ' + str(Nerror_best))\n",
    "\n",
    "for i in range(len(problem['names'])):\n",
    "    print('Parameter: ' + str(problem['names'][i]) + ' Best values: ' + str(round(BestParam_m[i],3)) + ' , ' +str(round(BestParam_N[i],3)) + ' and: ' +str(round(BestParam[i],3))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# II. Make a filtered array including only times of empiric measurement (remove from array results from times in which data was not measured)\n",
    "# III. Add relevant columns from df2_temp and the model results to a new df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y3.tolist().index(min(Y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = param_values[Y3.tolist().index(min(Y3))].tolist()\n",
    "X\n",
    "\n",
    "# [0.00448046875, 4.2197265625, 2.81181640625, 0.0103330078125, 25.60546875, 54.4921875, 21.7236328125,\n",
    "# 1.40556640625, 0.017607421875, 0.830078125, 23.14453125, 45.400390625, 19.794921875, 34.357421875, 5.2041015625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#miu = X[0]\n",
    "miu = 0.03\n",
    "lossess20 = X[0]\n",
    "Nintmax = X[1]\n",
    "Nintcrit = X[2]\n",
    "dNextoutdt = X[3]\n",
    "Ks = X[4]\n",
    "Vmax = X[5]\n",
    "KI = X[6]\n",
    "K0 = X[7]\n",
    "Ka = X[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n = 2\n",
    "# Visual calibration of high resolution data (data from sporulation events was excluded)\n",
    "\n",
    "# Calibration data - experiments #3 and #4 (black)\n",
    "# Validation data - experiments #1, #2 and #5 (orange)\n",
    "#Ka = 0.15\n",
    "\n",
    "TModAll = [] # Each sub-array has the time steps of a specific treatment (periods)\n",
    "mExpAllTimes_cal,NintExpAllTimes_cal,NextExpAllTimes_cal = [],[],[]\n",
    "mModAll,NintModAll,NextModAll = [],[],[]\n",
    "mExpAllTimes_val,NintExpAllTimes_val,NextExpAllTimes_val = [],[],[]\n",
    "mModAll_val,NintModAll_val,NextModAll_val = [],[],[]\n",
    "mExpAllTimes_spor,NintExpAllTimes_spor,NextExpAllTimes_spor = [],[],[]\n",
    "mModAll_spor,NintModAll_spor,NextModAll_spor = [],[],[]\n",
    "\n",
    "mTimeTemp_spor = 0\n",
    "\n",
    "Treatments = ['1000/1/168','500/2/168','500/3/168','2000/1/168','200/5/168']\n",
    "Nint0All = ['2.12','2.13','2.32','2.05','1.3']\n",
    "\n",
    "Temp = 22\n",
    "#I0 = 80\n",
    "S = 39 # fix salinity function and S=40\n",
    "\n",
    "df2_Reduced = df2[(df2.Treatment != 'Acclimation') & (df2.Week <= 3) & (df2.Stage != 'i') & (df2.Sporulated == 'No')&(df2.Comment != 'Exclude')]\n",
    "df2_cal = df2_Reduced[(df2_Reduced.Exp != 1)&(df2_Reduced.Exp != 2)&(df2_Reduced.Exp != 5)]\n",
    "df2_val = df2_Reduced[(np.isnan(df2_Reduced.DW) != True)&(df2_Reduced.Exp != 3)&(df2_Reduced.Exp != 4)]\n",
    "df2_spor = df2[(np.isnan(df2.DW) != True)&(df2.Treatment != 'Acclimation')&(df2.Duration == 168) & (df2.Week <= 3) & (df2.Stage != 'i') & (df2.Sporulated == 'Yes')&(df2.Comment != 'Exclude')]\n",
    "\n",
    "\n",
    "for i in Treatments:\n",
    "    print('\\nTreatment: ' + str(i))\n",
    "    # calibration data\n",
    "    df2Temp_cal = df2_cal[(df2_Reduced.Treatment == i)]\n",
    "    mTemp_cal = df2Temp_cal[(np.isnan(df2Temp_cal.DW) != True)]['DW']\n",
    "    mTimeTemp_cal = df2Temp_cal[(np.isnan(df2Temp_cal.DW) != True)]['T']\n",
    "    NintTemp_cal = df2Temp_cal[(np.isnan(df2Temp_cal.N) != True)]['N']\n",
    "    NintTimeTemp_cal = df2Temp_cal[(np.isnan(df2Temp_cal.N) != True)]['T']\n",
    "    NextTemp_cal = df2Temp_cal[(np.isnan(df2Temp_cal.NH4) != True)]['NH4']\n",
    "    NextTimeTemp_cal = df2Temp_cal[(np.isnan(df2Temp_cal.NH4) != True)]['T']\n",
    "    \n",
    "    # validation data\n",
    "    df2Temp_val = df2_val[(df2_Reduced.Treatment == i)]\n",
    "    mTemp_val = df2Temp_val[(np.isnan(df2Temp_val.DW) != True)]['DW']\n",
    "    mTimeTemp_val = df2Temp_val[(np.isnan(df2Temp_val.DW) != True)]['T']\n",
    "    NintTemp_val = df2Temp_val[(np.isnan(df2Temp_val.N) != True)]['N']\n",
    "    NintTimeTemp_val = df2Temp_val[(np.isnan(df2Temp_val.N) != True)]['T']\n",
    "    NextTemp_val = df2Temp_val[(np.isnan(df2Temp_val.NH4) != True)]['NH4']\n",
    "    NextTimeTemp_val = df2Temp_val[(np.isnan(df2Temp_val.NH4) != True)]['T']\n",
    "    mTemp_val = df2Temp_val[(~np.isnan(df2Temp_val.DW))]['DW']\n",
    "    mTimeTemp_val = df2Temp_val[(~np.isnan(df2Temp_val.DW))]['T']\n",
    "    NintTemp_val = df2Temp_val[(~np.isnan(df2Temp_val.N))]['N']\n",
    "    NintTimeTemp_val = df2Temp_val[(~np.isnan(df2Temp_val.N))]['T']\n",
    "    NextTemp_val = df2Temp_val[(~np.isnan(df2Temp_val.NH4))]['NH4']\n",
    "    NextTimeTemp_val = df2Temp_val[(~np.isnan(df2Temp_val.NH4))]['T']\n",
    "    \n",
    "    # sporulation data\n",
    "    del mTimeTemp_spor\n",
    "    df2Temp_spor = df2_spor[(df2_spor.Treatment == i)]\n",
    "    mTemp_spor = df2Temp_spor[(np.isnan(df2Temp_spor.DW) != True)]['DW']\n",
    "    mTimeTemp_spor = df2Temp_spor[(np.isnan(df2Temp_spor.DW) != True)]['T']\n",
    "    NintTemp_spor = df2Temp_spor[(np.isnan(df2Temp_spor.N) != True)]['N']\n",
    "    NintTimeTemp_spor = df2Temp_spor[(np.isnan(df2Temp_spor.N) != True)]['T']\n",
    "    NextTemp_spor = df2Temp_spor[(np.isnan(df2Temp_spor.NH4) != True)]['NH4']\n",
    "    NextTimeTemp_spor = df2Temp_spor[(np.isnan(df2Temp_spor.NH4) != True)]['T']\n",
    "    mTemp_spor = df2Temp_spor[(~np.isnan(df2Temp_spor.DW))]['DW']\n",
    "    mTimeTemp_spor = df2Temp_spor[(~np.isnan(df2Temp_spor.DW))]['T']\n",
    "    NintTemp_spor = df2Temp_spor[(~np.isnan(df2Temp_spor.N))]['N']\n",
    "    NintTimeTemp_spor = df2Temp_spor[(~np.isnan(df2Temp_spor.N))]['T']\n",
    "    NextTemp_spor = df2Temp_spor[(~np.isnan(df2Temp_spor.NH4))]['NH4']\n",
    "    NextTimeTemp_spor = df2Temp_spor[(~np.isnan(df2Temp_spor.NH4))]['T']\n",
    "    \n",
    "    print('Number of samples:\\nm: ' + str(len(mTimeTemp_cal)) + ' Nint: ' + str(len(NintTimeTemp_cal)) + ' Next: ' + str(len(NextTimeTemp_cal)))\n",
    "    \n",
    "    # Amplitude / Period / Duration parameters from input\n",
    "    Tr = []\n",
    "    Tr = i.split('/')\n",
    "    Tr = [float(i) for i in Tr]\n",
    "    Amplitude = Tr[0]\n",
    "    Period = float(7/Tr[1]) # Period is in hours\n",
    "    print(Period)\n",
    "    Duration = Tr[2]/24\n",
    "    \n",
    "    NEXT, NINT, M, TT = [],[],[],[]\n",
    "\n",
    "    n_days = Duration*3\n",
    "    count_periods = 0\n",
    "    \n",
    "    #T1 = '2019,02,14,17,0'\n",
    "    #T2 = df3Temp['Timei']\n",
    "    #T2 = T2.tolist()[0]\n",
    "    #t0 = Time_to_Hours(T1,T2)\n",
    "    \n",
    "    # hour = 0 is 1pm (Meiron)\n",
    "    # in the indoor settings we have to solve for shorter periods, \n",
    "    # at the beginning of the Treatment we reset Nint, Next, m\n",
    "    # at the beginning of each Period we set Next to the last Amplitude, \n",
    "    # m0 to the end of previous solution of ode()\n",
    "    # \n",
    "    \n",
    "    # Let's prepare the IO(t) function that will be supplied to odeint \n",
    "    # instead of a scalar. \n",
    "    \n",
    "    all_treatment_hours = np.arange(0,n_days*24,dtype=np.int)\n",
    "    \n",
    "    # 8pm on the first day is zero crossing of this one 8pm - 10m = 7 hours\n",
    "    offtimes = all_treatment_hours[np.mod(all_treatment_hours - 7,24) == 0]\n",
    "    offtimes = np.r_[offtimes,all_treatment_hours[-1]+1] # last hour would be whatever\n",
    "    \n",
    "    # 6am on the next day is zero crossing of this one, 6am - 8pm is 10 hours\n",
    "    ontimes = all_treatment_hours[np.mod(all_treatment_hours - 7 + 10,24) == 0]\n",
    "    # and the iniital hour as we always start at 1pm, during ontime\n",
    "    ontimes = np.r_[np.int(0),ontimes]\n",
    "    \n",
    "    # prepare the duty cycle\n",
    "    I0set = np.zeros_like(all_treatment_hours)\n",
    "    for s,e in zip(ontimes,offtimes):\n",
    "        I0set[s:e] = 80\n",
    "        \n",
    "    # if you want to replace it by a \"constant\" I0 then replace the lines above with\n",
    "    # the following line and then it will also give you a constant solution you had before\n",
    "    \n",
    "    # I0set = np.ones_like(all_treatment_hours)*80\n",
    "\n",
    "    \n",
    "    I0 = interpolate.interp1d(all_treatment_hours, I0set, bounds_error=False, fill_value=\"extrapolate\")\n",
    "    \n",
    "    for hour in np.arange(0,n_days*24,round(Period*24,0)):\n",
    "        print(hour)\n",
    "        if hour == 0:\n",
    "            print('Starting point')\n",
    "            Nint_0 = Nint0All[Treatments.index(i)]\n",
    "            m_0 = m0\n",
    "            Next_0 = Amplitude\n",
    "        \n",
    "        if hour > 0 and np.mod(hour,round(Period*24,0)) == 0:\n",
    "            count_periods = count_periods + 1\n",
    "            \n",
    "            if count_periods == Tr[1]:\n",
    "                print('Duration')\n",
    "                # reset everything, except Nint\n",
    "                Nint_0 = NINT[-1][-1]\n",
    "                Next_0 = Amplitude\n",
    "                m_0 = m0\n",
    "                count_periods = 0\n",
    "            else:\n",
    "                # period passed, not Duration\n",
    "                # add amplitude, keep going \n",
    "                print('Period')\n",
    "                Next_0 = NEXT[-1][-1] + Amplitude\n",
    "                Nint_0 = NINT[-1][-1]\n",
    "                m_0 = M[-1][-1]\n",
    "   \n",
    "                \n",
    "        # Here we want to send odeint the times of the light sub-period or \n",
    "        # darkness sub-period\n",
    "\n",
    "        x0 = [Next_0,Nint_0,m_0]\n",
    "        # t = np.linspace(hour,hour+Period*24) # every time we solve ODE for 24 hours * Period\n",
    "        t = np.arange(hour, hour+Period*24) # can also ask for report on round hours\n",
    "\n",
    "        x = odeint(controlled_N_constST,x0,t,args=(Nintmax,Nintmin,Vmax,Ks,dNextoutdt,dNextindt,miu,dmoutdt,Nintcrit,Z,KI,K0,Ka,\n",
    "                losses20,teta,umol_to_percent_DW,I0,Temp),printmessg=0,hmax=.1)\n",
    "\n",
    "        NEXT.append(x[: , 0])\n",
    "        NINT.append(x[: , 1])\n",
    "        M.append(x[: , 2])\n",
    "        TT.append(t)\n",
    "        \n",
    "        t_model = np.hstack(TT)\n",
    "        Next_model = np.hstack(NEXT)\n",
    "        Nint_model = np.hstack(NINT)\n",
    "        m_model = np.hstack(M)\n",
    "\n",
    "    TModAll.append(TT)\n",
    "    #Calibration experimental data\n",
    "    mExpAllTimes_cal.append(mTimeTemp_cal)\n",
    "    NintExpAllTimes_cal.append(NintTimeTemp_cal)\n",
    "    NextExpAllTimes_cal.append(NextTimeTemp_cal)\n",
    "    \n",
    "    #model data\n",
    "    mModAll.append(m_model)\n",
    "    NintModAll.append(Nint_model)\n",
    "    NextModAll.append(Next_model)\n",
    "    \n",
    "    #Valiaation experimental data\n",
    "    mExpAllTimes_val.append(mTimeTemp_val)\n",
    "    NintExpAllTimes_val.append(NintTimeTemp_val)\n",
    "    NextExpAllTimes_val.append(NextTimeTemp_val)\n",
    "    \n",
    "    #Sporulation experimental data\n",
    "    if len(mTimeTemp_spor) > 0: #np.empty(mTimeTemp_spor) != True:\n",
    "        mExpAllTimes_spor.append(mTimeTemp_spor)\n",
    "        NintExpAllTimes_spor.append(NintTimeTemp_spor)\n",
    "        NextExpAllTimes_spor.append(NextTimeTemp_spor)\n",
    "    \n",
    "\n",
    "    # error bars according to calibration error\n",
    "    yerrm1,yerrNext1,yerrNint1 = [],[],[]\n",
    "    for i in m_model:\n",
    "        yerrm1.append(0.202*i)\n",
    "    for i in Nint_model:\n",
    "        yerrNint1.append(0.202*i)\n",
    "    for i in Next_model:\n",
    "        yerrNext1.append(0.165*i)\n",
    "    \n",
    "    plot_result_extra(t_model,Next_model,Nint_model,m_model,Nint=NintTemp_cal,yerrNint=yerrNint1,tNint=NintTimeTemp_cal,m=mTemp_cal,yerrm=yerrm1,tm=mTimeTemp_cal,Next=NextTemp_cal,yerrNext=yerrNext1,tNext=NextTimeTemp_cal,Next_val = NextTemp_val,tNext_val =NextTimeTemp_val,Nint_val = NintTemp_val,tNint_val =NintTimeTemp_val,m_val = mTemp_val,tm_val =mTimeTemp_val,Next_spor = NextTemp_spor,tNext_spor =NextTimeTemp_spor,Nint_spor = NintTemp_spor,tNint_spor =NintTimeTemp_spor,m_spor = mTemp_spor,tm_spor =mTimeTemp_spor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration data error - step 1: calculte model prediction for each measurement\n",
    "\n",
    "# This cell adjusts measurment time to model durations - so that maximum biomass measurements\n",
    "# are compared to maximum biomass predictions and not to the initial stocking density (m0)\n",
    "\n",
    "\n",
    "# constrain times to end at 504 hours\n",
    "TModTemp = []\n",
    "TModAllOrg = []\n",
    "mModReducedAll, NintModReducedAll, NextModReducedAll = [],[],[]\n",
    "for i in range(len(TModAll)): # loops over 5 treatments\n",
    "    print(i)\n",
    "    for j in range(len(TModAll[i])): # Loops over periods in each treatment\n",
    "        Ttemp = TModAll[i][j]\n",
    "        for k in Ttemp: #The model ends at 504 hours, but some measurement reach also 50 hours. This sets a 504 hour limit\n",
    "            if k > 504:\n",
    "                k = 504\n",
    "            TModTemp.append(k)\n",
    "    TModAllOrg.append(TModTemp)\n",
    "    TModTemp = []\n",
    "\n",
    "mExpAllTimes_cal_new = []\n",
    "for i in range(len(TModAll)):\n",
    "    \n",
    "    # Calculate m model predictions - if time is out of bounderies, maximal model value is chosen\n",
    "    gm = interpolate.interp1d(TModAllOrg[i], mModAll[i],kind = 'linear')\n",
    "    mModReduced = []\n",
    "    for j in mExpAllTimes_cal[i]:\n",
    "        if j >= 168 and j < 180:\n",
    "            j = 167.9\n",
    "        elif j >= 336 and j < 345:\n",
    "            j = 335.9\n",
    "        elif j > 504:\n",
    "            j = 504\n",
    "        mModReduced.append(gm(j-1))\n",
    "    mModReducedAll.append(mModReduced)  \n",
    "    \n",
    "    # Calculate Nint model predictions - if time is out of bounderies, maximal model value is chosen\n",
    "    gNint = interpolate.interp1d(TModAllOrg[i], NintModAll[i],kind = 'linear')\n",
    "    NintModReduced = []\n",
    "    for j in NintExpAllTimes_cal[i]:\n",
    "        if j >= 168 and j < 180:\n",
    "            j = 167.9\n",
    "        if j >= 336 and j < 345:\n",
    "            j = 335.9\n",
    "        if j > 504:\n",
    "            j = 504\n",
    "        NintModReduced.append(gNint(j-1))\n",
    "    NintModReducedAll.append(NintModReduced)\n",
    "    \n",
    "    # Calculate Next model predictions - if time is out of bounderies, maximal model value is chosen\n",
    "    gNext = interpolate.interp1d(TModAllOrg[i], NextModAll[i],kind = 'linear')    \n",
    "    NextModReduced = []\n",
    "    for j in NextExpAllTimes_cal[i]:\n",
    "        if j >= 168 and j < 180:\n",
    "            j = 167.9\n",
    "        if j >= 336 and j < 345:\n",
    "            j = 335.9\n",
    "        if j > 504:\n",
    "            j = 504\n",
    "        NextModReduced.append(gNext(j-1))\n",
    "    NextModReducedAll.append(NextModReduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration data error - step 2: calculte errors for each variable\n",
    "\n",
    "mSRE_All,NintSRE_All,NextSRE_All = [],[],[]\n",
    "for i in range(len(Treatments)):\n",
    "    mSRE,NintSRE,NextSRE = [],[],[]\n",
    "    \n",
    "    # Biomass\n",
    "    \n",
    "    df2m = df2_Reduced[(np.isnan(df2_Reduced.DW) != True)&(df2_Reduced.Exp != 1)&(df2_Reduced.Exp != 2)&(df2_Reduced.Exp != 5)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "\n",
    "    print('Treatment: ' + str(Treatments[i]) + '\\n\\nm\\n')\n",
    "    print('Number of samples: ' + str(len(df2m.Sample)) + '\\n')\n",
    "    k = 0\n",
    "    for j in df2m.Sample: # loop over all samples\n",
    "        mexp = df2m.DW # measured m\n",
    "        mmod = mModReducedAll[i] # predicted m\n",
    "        mSRE.append(((mexp.iloc[k]-mmod[k])/mmod[k])**2) # Square relative error\n",
    "        print('Sample #' + str(math.floor(float(j))))\n",
    "        print('Measured biomass: ' + str(round(mexp.iloc[k],3)))\n",
    "        print('Modeled biomass: ' + str(round(float(mmod[k]),3)) + '\\n')\n",
    "        print('Relative Error: ' + str(round(float(mSRE[k]**0.5),3)) + '\\n')\n",
    "        mSRE_All.append((((mexp.iloc[k]-mmod[k])/mmod[k])**2)) # All Square Relative Errors\n",
    "        k = k + 1\n",
    "    RMSREm = round((np.mean(mSRE))**0.5,3) # Root Mean Square relative error\n",
    "    \n",
    "    print('The RMSRE of m in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSREm) + '\\n')\n",
    "    print('end of treatment ' + str(Treatments[i]) + '\\n')\n",
    "    \n",
    "    # Internal N\n",
    "    df2Nint = df2_Reduced[(np.isnan(df2_Reduced.N) != True)&(df2_Reduced.Exp != 1)&(df2_Reduced.Exp != 2)&(df2_Reduced.Exp != 5)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "\n",
    "    print('\\nNint\\n')\n",
    "    print('Number of samples: ' + str(len(df2Nint.Sample)) + '\\n')\n",
    "    k = 0\n",
    "    for j in df2Nint.Sample: # loop over all samples\n",
    "        Nintexp = df2Nint.N # measured Nint\n",
    "        Nintmod = NintModReducedAll[i] # predicted Nint\n",
    "        NintSRE.append(((Nintexp.iloc[k]-Nintmod[k])/Nintmod[k])**2) # Square relative error\n",
    "        print('Sample #' + str(math.floor(float(j))))\n",
    "        print('Measured Nint: ' + str(round(float(Nintexp.iloc[k]),3)))     \n",
    "        print('Modeled Nint: ' + str(round(float(Nintmod[k]),3)) + '\\n')        \n",
    "        NintSRE_All.append(((Nintexp.iloc[k]-Nintmod[k])/Nintmod[k])**2) # All Square Relative Errors\n",
    "        k = k + 1\n",
    "    RMSRENint = round((np.mean(NintSRE))**0.5,3) #RMSRE\n",
    "    \n",
    "    print('\\nThe RMSRE of Nint in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSRENint) + '\\n')\n",
    "    \n",
    "    # External N\n",
    "    df2Next = df2_Reduced[(np.isnan(df2_Reduced.NH4) != True)&(df2_Reduced.Exp != 1)&(df2_Reduced.Exp != 2)&(df2_Reduced.Exp != 5)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "    print('\\nNext\\n')\n",
    "    print('Number of samples: ' + str(len(df2Next.Sample)) + '\\n')\n",
    "    k = 0\n",
    "    for j in df2Next.Sample:\n",
    "        Nextexp = df2Next.NH4\n",
    "        if Nextexp.iloc[k] < 0:\n",
    "            Nextexp.iloc[k] = 0\n",
    "        Nextmod = NextModReducedAll[i]\n",
    "        NextSRE.append(((Nextexp.iloc[k]-Nextmod[k])/Nextmod[k])**2)\n",
    "        print('Sample #' + str(math.floor(float(j))))\n",
    "        print('Measured Next: ' + str(round(float(Nextexp.iloc[k]),3)))     \n",
    "        print('Modeled Next: ' + str(round(float(Nextmod[k]),3)) + '\\n')        \n",
    "        k = k + 1\n",
    "    RMSRENext = round((np.mean(NextSRE))**0.5,3)\n",
    "    NextSRE_All.append(NextSRE)\n",
    "    print('\\nThe RMSRE of Next in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSRENext) + '\\n')\n",
    "print('End of treatment ' + str(Treatments[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biomass model error of calibration data\n",
    "\n",
    "RMSREm = round((np.mean(mSRE_All))**0.5,3)\n",
    "print(RMSREm)\n",
    "#0.154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nint model error of calibration data\n",
    "\n",
    "\n",
    "RMSRENint = round((np.mean(NintSRE_All))**0.5,3)\n",
    "print(RMSRENint)\n",
    "#0.232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print errors:\n",
    "RMSREm = round((np.mean(mSRE_All))**0.5,3)\n",
    "RMSRENint = round((np.mean(NintSRE_All))**0.5,3)\n",
    "\n",
    "print('\\nError of m is: ' + str(RMSREm))\n",
    "print('\\nError of Nint is: ' + str(RMSRENint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miu = 0.03\n",
    "#miu = X[0]\n",
    "lossess20 = 0.004\n",
    "Nintmax = 4.5\n",
    "Nintcrit = 1.6 #1.7 #1.8 #2.3 #2\n",
    "dNextoutdt = 0.015 #0.01\n",
    "Ks = 23 #15.5\n",
    "Vmax = 60 # 50\n",
    "KI = 16\n",
    "K0 = 0.5 #2# 2.4\n",
    "Ka = 0.1 #0.085 #0.07 #0.12\n",
    "Smin = 0\n",
    "Sopt = 28\n",
    "Smax = 50\n",
    "Topt = 18\n",
    "Tmax = 35.9\n",
    "n = 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n = 2\n",
    "# Visual calibration of high resolution data (data from sporulation events was excluded)\n",
    "\n",
    "# Calibration data - experiments #3 and #4 (black)\n",
    "# Validation data - experiments #1, #2 and #5 (orange)\n",
    "#Ka = 0.15\n",
    "\n",
    "TModAll = [] # Each sub-array has the time steps of a specific treatment (periods)\n",
    "mExpAllTimes_cal,NintExpAllTimes_cal,NextExpAllTimes_cal = [],[],[]\n",
    "mModAll,NintModAll,NextModAll = [],[],[]\n",
    "mExpAllTimes_val,NintExpAllTimes_val,NextExpAllTimes_val = [],[],[]\n",
    "mModAll_val,NintModAll_val,NextModAll_val = [],[],[]\n",
    "mExpAllTimes_spor,NintExpAllTimes_spor,NextExpAllTimes_spor = [],[],[]\n",
    "mModAll_spor,NintModAll_spor,NextModAll_spor = [],[],[]\n",
    "\n",
    "mTimeTemp_spor = 0\n",
    "\n",
    "Treatments = ['1000/1/168','500/2/168','500/3/168','2000/1/168','200/5/168']\n",
    "Nint0All = ['2.12','2.13','2.32','2.05','1.3']\n",
    "\n",
    "Temp = 22\n",
    "#I0 = 80\n",
    "S = 39 # fix salinity function and S=40\n",
    "\n",
    "df2_Reduced = df2[(df2.Treatment != 'Acclimation') & (df2.Week <= 3) & (df2.Stage != 'i') & (df2.Sporulated == 'No')&(df2.Comment != 'Exclude')]\n",
    "df2_cal = df2_Reduced[(df2_Reduced.Exp != 1)&(df2_Reduced.Exp != 2)&(df2_Reduced.Exp != 5)]\n",
    "df2_val = df2_Reduced[(np.isnan(df2_Reduced.DW) != True)&(df2_Reduced.Exp != 3)&(df2_Reduced.Exp != 4)]\n",
    "df2_spor = df2[(np.isnan(df2.DW) != True)&(df2.Treatment != 'Acclimation')&(df2.Duration == 168) & (df2.Week <= 3) & (df2.Stage != 'i') & (df2.Sporulated == 'Yes')&(df2.Comment != 'Exclude')]\n",
    "\n",
    "\n",
    "for i in Treatments:\n",
    "    print('\\nTreatment: ' + str(i))\n",
    "    # calibration data\n",
    "    df2Temp_cal = df2_cal[(df2_Reduced.Treatment == i)]\n",
    "    mTemp_cal = df2Temp_cal[(np.isnan(df2Temp_cal.DW) != True)]['DW']\n",
    "    mTimeTemp_cal = df2Temp_cal[(np.isnan(df2Temp_cal.DW) != True)]['T']\n",
    "    NintTemp_cal = df2Temp_cal[(np.isnan(df2Temp_cal.N) != True)]['N']\n",
    "    NintTimeTemp_cal = df2Temp_cal[(np.isnan(df2Temp_cal.N) != True)]['T']\n",
    "    NextTemp_cal = df2Temp_cal[(np.isnan(df2Temp_cal.NH4) != True)]['NH4']\n",
    "    NextTimeTemp_cal = df2Temp_cal[(np.isnan(df2Temp_cal.NH4) != True)]['T']\n",
    "    \n",
    "    # validation data\n",
    "    df2Temp_val = df2_val[(df2_Reduced.Treatment == i)]\n",
    "    mTemp_val = df2Temp_val[(np.isnan(df2Temp_val.DW) != True)]['DW']\n",
    "    mTimeTemp_val = df2Temp_val[(np.isnan(df2Temp_val.DW) != True)]['T']\n",
    "    NintTemp_val = df2Temp_val[(np.isnan(df2Temp_val.N) != True)]['N']\n",
    "    NintTimeTemp_val = df2Temp_val[(np.isnan(df2Temp_val.N) != True)]['T']\n",
    "    NextTemp_val = df2Temp_val[(np.isnan(df2Temp_val.NH4) != True)]['NH4']\n",
    "    NextTimeTemp_val = df2Temp_val[(np.isnan(df2Temp_val.NH4) != True)]['T']\n",
    "    mTemp_val = df2Temp_val[(~np.isnan(df2Temp_val.DW))]['DW']\n",
    "    mTimeTemp_val = df2Temp_val[(~np.isnan(df2Temp_val.DW))]['T']\n",
    "    NintTemp_val = df2Temp_val[(~np.isnan(df2Temp_val.N))]['N']\n",
    "    NintTimeTemp_val = df2Temp_val[(~np.isnan(df2Temp_val.N))]['T']\n",
    "    NextTemp_val = df2Temp_val[(~np.isnan(df2Temp_val.NH4))]['NH4']\n",
    "    NextTimeTemp_val = df2Temp_val[(~np.isnan(df2Temp_val.NH4))]['T']\n",
    "    \n",
    "    # sporulation data\n",
    "    del mTimeTemp_spor\n",
    "    df2Temp_spor = df2_spor[(df2_spor.Treatment == i)]\n",
    "    mTemp_spor = df2Temp_spor[(np.isnan(df2Temp_spor.DW) != True)]['DW']\n",
    "    mTimeTemp_spor = df2Temp_spor[(np.isnan(df2Temp_spor.DW) != True)]['T']\n",
    "    NintTemp_spor = df2Temp_spor[(np.isnan(df2Temp_spor.N) != True)]['N']\n",
    "    NintTimeTemp_spor = df2Temp_spor[(np.isnan(df2Temp_spor.N) != True)]['T']\n",
    "    NextTemp_spor = df2Temp_spor[(np.isnan(df2Temp_spor.NH4) != True)]['NH4']\n",
    "    NextTimeTemp_spor = df2Temp_spor[(np.isnan(df2Temp_spor.NH4) != True)]['T']\n",
    "    mTemp_spor = df2Temp_spor[(~np.isnan(df2Temp_spor.DW))]['DW']\n",
    "    mTimeTemp_spor = df2Temp_spor[(~np.isnan(df2Temp_spor.DW))]['T']\n",
    "    NintTemp_spor = df2Temp_spor[(~np.isnan(df2Temp_spor.N))]['N']\n",
    "    NintTimeTemp_spor = df2Temp_spor[(~np.isnan(df2Temp_spor.N))]['T']\n",
    "    NextTemp_spor = df2Temp_spor[(~np.isnan(df2Temp_spor.NH4))]['NH4']\n",
    "    NextTimeTemp_spor = df2Temp_spor[(~np.isnan(df2Temp_spor.NH4))]['T']\n",
    "    \n",
    "    print('Number of samples:\\nm: ' + str(len(mTimeTemp_cal)) + ' Nint: ' + str(len(NintTimeTemp_cal)) + ' Next: ' + str(len(NextTimeTemp_cal)))\n",
    "    \n",
    "    # Amplitude / Period / Duration parameters from input\n",
    "    Tr = []\n",
    "    Tr = i.split('/')\n",
    "    Tr = [float(i) for i in Tr]\n",
    "    Amplitude = Tr[0]\n",
    "    Period = float(7/Tr[1]) # Period is in hours\n",
    "    print(Period)\n",
    "    Duration = Tr[2]/24\n",
    "    \n",
    "    NEXT, NINT, M, TT = [],[],[],[]\n",
    "\n",
    "    n_days = Duration*3\n",
    "    count_periods = 0\n",
    "    \n",
    "    #T1 = '2019,02,14,17,0'\n",
    "    #T2 = df3Temp['Timei']\n",
    "    #T2 = T2.tolist()[0]\n",
    "    #t0 = Time_to_Hours(T1,T2)\n",
    "    \n",
    "    # hour = 0 is 1pm (Meiron)\n",
    "    # in the indoor settings we have to solve for shorter periods, \n",
    "    # at the beginning of the Treatment we reset Nint, Next, m\n",
    "    # at the beginning of each Period we set Next to the last Amplitude, \n",
    "    # m0 to the end of previous solution of ode()\n",
    "    # \n",
    "    \n",
    "    # Let's prepare the IO(t) function that will be supplied to odeint \n",
    "    # instead of a scalar. \n",
    "    \n",
    "    all_treatment_hours = np.arange(0,n_days*24,dtype=np.int)\n",
    "    \n",
    "    # 8pm on the first day is zero crossing of this one 8pm - 10m = 7 hours\n",
    "    offtimes = all_treatment_hours[np.mod(all_treatment_hours - 7,24) == 0]\n",
    "    offtimes = np.r_[offtimes,all_treatment_hours[-1]+1] # last hour would be whatever\n",
    "    \n",
    "    # 6am on the next day is zero crossing of this one, 6am - 8pm is 10 hours\n",
    "    ontimes = all_treatment_hours[np.mod(all_treatment_hours - 7 + 10,24) == 0]\n",
    "    # and the iniital hour as we always start at 1pm, during ontime\n",
    "    ontimes = np.r_[np.int(0),ontimes]\n",
    "    \n",
    "    # prepare the duty cycle\n",
    "    I0set = np.zeros_like(all_treatment_hours)\n",
    "    for s,e in zip(ontimes,offtimes):\n",
    "        I0set[s:e] = 80\n",
    "        \n",
    "    # if you want to replace it by a \"constant\" I0 then replace the lines above with\n",
    "    # the following line and then it will also give you a constant solution you had before\n",
    "    \n",
    "    # I0set = np.ones_like(all_treatment_hours)*80\n",
    "\n",
    "    \n",
    "    I0 = interpolate.interp1d(all_treatment_hours, I0set, bounds_error=False, fill_value=\"extrapolate\")\n",
    "    \n",
    "    for hour in np.arange(0,n_days*24,round(Period*24,0)):\n",
    "        print(hour)\n",
    "        if hour == 0:\n",
    "            print('Starting point')\n",
    "            Nint_0 = Nint0All[Treatments.index(i)]\n",
    "            m_0 = m0\n",
    "            Next_0 = Amplitude\n",
    "        \n",
    "        if hour > 0 and np.mod(hour,round(Period*24,0)) == 0:\n",
    "            count_periods = count_periods + 1\n",
    "            \n",
    "            if count_periods == Tr[1]:\n",
    "                print('Duration')\n",
    "                # reset everything, except Nint\n",
    "                Nint_0 = NINT[-1][-1]\n",
    "                Next_0 = Amplitude\n",
    "                m_0 = m0\n",
    "                count_periods = 0\n",
    "            else:\n",
    "                # period passed, not Duration\n",
    "                # add amplitude, keep going \n",
    "                print('Period')\n",
    "                Next_0 = NEXT[-1][-1] + Amplitude\n",
    "                Nint_0 = NINT[-1][-1]\n",
    "                m_0 = M[-1][-1]\n",
    "   \n",
    "                \n",
    "        # Here we want to send odeint the times of the light sub-period or \n",
    "        # darkness sub-period\n",
    "\n",
    "        x0 = [Next_0,Nint_0,m_0]\n",
    "        # t = np.linspace(hour,hour+Period*24) # every time we solve ODE for 24 hours * Period\n",
    "        t = np.arange(hour, hour+Period*24) # can also ask for report on round hours\n",
    "\n",
    "        x = odeint(controlled_N_new,x0,t,args=(Nintmax,Nintmin,Vmax,Ks,dNextoutdt,dNextindt,miu,dmoutdt,Nintcrit,S,Z,KI,K0,Ka,\n",
    "                                               Topt,Tmin,Tmax,losses20,teta,Sopt,Smin,Smax,n,umol_to_percent_DW,Temp,I0),printmessg=0,hmax=.1)\n",
    "\n",
    "        NEXT.append(x[: , 0])\n",
    "        NINT.append(x[: , 1])\n",
    "        M.append(x[: , 2])\n",
    "        TT.append(t)\n",
    "        \n",
    "        t_model = np.hstack(TT)\n",
    "        Next_model = np.hstack(NEXT)\n",
    "        Nint_model = np.hstack(NINT)\n",
    "        m_model = np.hstack(M)\n",
    "\n",
    "    TModAll.append(TT)\n",
    "    #Calibration experimental data\n",
    "    mExpAllTimes_cal.append(mTimeTemp_cal)\n",
    "    NintExpAllTimes_cal.append(NintTimeTemp_cal)\n",
    "    NextExpAllTimes_cal.append(NextTimeTemp_cal)\n",
    "    \n",
    "    #model data\n",
    "    mModAll.append(m_model)\n",
    "    NintModAll.append(Nint_model)\n",
    "    NextModAll.append(Next_model)\n",
    "    \n",
    "    #Valiaation experimental data\n",
    "    mExpAllTimes_val.append(mTimeTemp_val)\n",
    "    NintExpAllTimes_val.append(NintTimeTemp_val)\n",
    "    NextExpAllTimes_val.append(NextTimeTemp_val)\n",
    "    \n",
    "    #Sporulation experimental data\n",
    "    if len(mTimeTemp_spor) > 0: #np.empty(mTimeTemp_spor) != True:\n",
    "        mExpAllTimes_spor.append(mTimeTemp_spor)\n",
    "        NintExpAllTimes_spor.append(NintTimeTemp_spor)\n",
    "        NextExpAllTimes_spor.append(NextTimeTemp_spor)\n",
    "    \n",
    "    #Validation model data\n",
    "    #mModAll_val.append(m_model_val)\n",
    "    #NintModAll_val.append(Nint_model_val)\n",
    "    #NextModAll_val.append(Next_model_val) \n",
    "    \n",
    "    #plot_result(t_model,Next_model,Nint_model,m_model,Nint=NintTemp,tNint=NintTimeTemp,m=mTemp,tm=mTimeTemp,Next=NextTemp,tNext=NextTimeTemp)\n",
    "    #plot_result_extra(t_model,Next_model,Nint_model,m_model,Nint=NintTemp_val,tNint=NintTimeTemp_val,m=mTemp_val,tm=mTimeTemp_val,Next=NextTemp_val,tNext=NextTimeTemp_val)\n",
    "    #plot_result_extra(t_model,Next_model,Nint_model,m_model,Nint=NintTemp_cal,tNint=NintTimeTemp_cal,m=mTemp_cal,tm=mTimeTemp_cal,Next=NextTemp_cal,tNext=NextTimeTemp_cal,Next_val = NextTemp_val,tNext_val =NextTimeTemp_val,Nint_val = NintTemp_val,tNint_val =NintTimeTemp_val,m_val = mTemp_val,tm_val =mTimeTemp_val )\n",
    "    plot_result_extra(t_model,Next_model,Nint_model,m_model,Nint=NintTemp_cal,tNint=NintTimeTemp_cal,m=mTemp_cal,tm=mTimeTemp_cal,Next=NextTemp_cal,tNext=NextTimeTemp_cal,Next_val = NextTemp_val,tNext_val =NextTimeTemp_val,Nint_val = NintTemp_val,tNint_val =NintTimeTemp_val,m_val = mTemp_val,tm_val =mTimeTemp_val,Next_spor = NextTemp_spor,tNext_spor =NextTimeTemp_spor,Nint_spor = NintTemp_spor,tNint_spor =NintTimeTemp_spor,m_spor = mTemp_spor,tm_spor =mTimeTemp_spor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration data error - step 1: calculte model prediction for each measurement\n",
    "\n",
    "# This cell adjusts measurment time to model durations - so that maximum biomass measurements\n",
    "# are compared to maximum biomass predictions and not to the initial stocking density (m0)\n",
    "\n",
    "\n",
    "# constrain times to end at 504 hours\n",
    "TModTemp = []\n",
    "TModAllOrg = []\n",
    "mModReducedAll, NintModReducedAll, NextModReducedAll = [],[],[]\n",
    "for i in range(len(TModAll)): # loops over 5 treatments\n",
    "    print(i)\n",
    "    for j in range(len(TModAll[i])): # Loops over periods in each treatment\n",
    "        Ttemp = TModAll[i][j]\n",
    "        for k in Ttemp: #The model ends at 504 hours, but some measurement reach also 50 hours. This sets a 504 hour limit\n",
    "            if k > 504:\n",
    "                k = 504\n",
    "            TModTemp.append(k)\n",
    "    TModAllOrg.append(TModTemp)\n",
    "    TModTemp = []\n",
    "\n",
    "mExpAllTimes_cal_new = []\n",
    "for i in range(len(TModAll)):\n",
    "    \n",
    "    # Calculate m model predictions - if time is out of bounderies, maximal model value is chosen\n",
    "    gm = interpolate.interp1d(TModAllOrg[i], mModAll[i],kind = 'linear')\n",
    "    mModReduced = []\n",
    "    for j in mExpAllTimes_cal[i]:\n",
    "        if j >= 168 and j < 180:\n",
    "            j = 167.9\n",
    "        elif j >= 336 and j < 345:\n",
    "            j = 335.9\n",
    "        elif j > 504:\n",
    "            j = 504\n",
    "        mModReduced.append(gm(j-1))\n",
    "    mModReducedAll.append(mModReduced)  \n",
    "    \n",
    "    # Calculate Nint model predictions - if time is out of bounderies, maximal model value is chosen\n",
    "    gNint = interpolate.interp1d(TModAllOrg[i], NintModAll[i],kind = 'linear')\n",
    "    NintModReduced = []\n",
    "    for j in NintExpAllTimes_cal[i]:\n",
    "        if j >= 168 and j < 180:\n",
    "            j = 167.9\n",
    "        if j >= 336 and j < 345:\n",
    "            j = 335.9\n",
    "        if j > 504:\n",
    "            j = 504\n",
    "        NintModReduced.append(gNint(j-1))\n",
    "    NintModReducedAll.append(NintModReduced)\n",
    "    \n",
    "    # Calculate Next model predictions - if time is out of bounderies, maximal model value is chosen\n",
    "    gNext = interpolate.interp1d(TModAllOrg[i], NextModAll[i],kind = 'linear')    \n",
    "    NextModReduced = []\n",
    "    for j in NextExpAllTimes_cal[i]:\n",
    "        if j >= 168 and j < 180:\n",
    "            j = 167.9\n",
    "        if j >= 336 and j < 345:\n",
    "            j = 335.9\n",
    "        if j > 504:\n",
    "            j = 504\n",
    "        NextModReduced.append(gNext(j-1))\n",
    "    NextModReducedAll.append(NextModReduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration data error - step 2: calculte errors for each variable\n",
    "\n",
    "mSRE_All,NintSRE_All,NextSRE_All = [],[],[]\n",
    "for i in range(len(Treatments)):\n",
    "    mSRE,NintSRE,NextSRE = [],[],[]\n",
    "    \n",
    "    # Biomass\n",
    "    \n",
    "    df2m = df2_Reduced[(np.isnan(df2_Reduced.DW) != True)&(df2_Reduced.Exp != 1)&(df2_Reduced.Exp != 2)&(df2_Reduced.Exp != 5)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "\n",
    "    print('Treatment: ' + str(Treatments[i]) + '\\n\\nm\\n')\n",
    "    print('Number of samples: ' + str(len(df2m.Sample)) + '\\n')\n",
    "    k = 0\n",
    "    for j in df2m.Sample: # loop over all samples\n",
    "        mexp = df2m.DW # measured m\n",
    "        mmod = mModReducedAll[i] # predicted m\n",
    "        mSRE.append(((mexp.iloc[k]-mmod[k])/mmod[k])**2) # Square relative error\n",
    "        print('Sample #' + str(math.floor(float(j))))\n",
    "        print('Measured biomass: ' + str(round(mexp.iloc[k],3)))\n",
    "        print('Modeled biomass: ' + str(round(float(mmod[k]),3)) + '\\n')\n",
    "        print('Relative Error: ' + str(round(float(mSRE[k]**0.5),3)) + '\\n')\n",
    "        mSRE_All.append((((mexp.iloc[k]-mmod[k])/mmod[k])**2)) # All Square Relative Errors\n",
    "        k = k + 1\n",
    "    RMSREm = round((np.mean(mSRE))**0.5,3) # Root Mean Square relative error\n",
    "    \n",
    "    print('The RMSRE of m in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSREm) + '\\n')\n",
    "    print('end of treatment ' + str(Treatments[i]) + '\\n')\n",
    "    \n",
    "    # Internal N\n",
    "    df2Nint = df2_Reduced[(np.isnan(df2_Reduced.N) != True)&(df2_Reduced.Exp != 1)&(df2_Reduced.Exp != 2)&(df2_Reduced.Exp != 5)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "\n",
    "    print('\\nNint\\n')\n",
    "    print('Number of samples: ' + str(len(df2Nint.Sample)) + '\\n')\n",
    "    k = 0\n",
    "    for j in df2Nint.Sample: # loop over all samples\n",
    "        Nintexp = df2Nint.N # measured Nint\n",
    "        Nintmod = NintModReducedAll[i] # predicted Nint\n",
    "        NintSRE.append(((Nintexp.iloc[k]-Nintmod[k])/Nintmod[k])**2) # Square relative error\n",
    "        print('Sample #' + str(math.floor(float(j))))\n",
    "        print('Measured Nint: ' + str(round(float(Nintexp.iloc[k]),3)))     \n",
    "        print('Modeled Nint: ' + str(round(float(Nintmod[k]),3)) + '\\n')        \n",
    "        NintSRE_All.append(((Nintexp.iloc[k]-Nintmod[k])/Nintmod[k])**2) # All Square Relative Errors\n",
    "        k = k + 1\n",
    "    RMSRENint = round((np.mean(NintSRE))**0.5,3) #RMSRE\n",
    "    \n",
    "    print('\\nThe RMSRE of Nint in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSRENint) + '\\n')\n",
    "    \n",
    "    # External N\n",
    "    df2Next = df2_Reduced[(np.isnan(df2_Reduced.NH4) != True)&(df2_Reduced.Exp != 1)&(df2_Reduced.Exp != 2)&(df2_Reduced.Exp != 5)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "    print('\\nNext\\n')\n",
    "    print('Number of samples: ' + str(len(df2Next.Sample)) + '\\n')\n",
    "    k = 0\n",
    "    for j in df2Next.Sample:\n",
    "        Nextexp = df2Next.NH4\n",
    "        if Nextexp.iloc[k] < 0:\n",
    "            Nextexp.iloc[k] = 0\n",
    "        Nextmod = NextModReducedAll[i]\n",
    "        NextSRE.append(((Nextexp.iloc[k]-Nextmod[k])/Nextmod[k])**2)\n",
    "        print('Sample #' + str(math.floor(float(j))))\n",
    "        print('Measured Next: ' + str(round(float(Nextexp.iloc[k]),3)))     \n",
    "        print('Modeled Next: ' + str(round(float(Nextmod[k]),3)) + '\\n')        \n",
    "        k = k + 1\n",
    "    RMSRENext = round((np.mean(NextSRE))**0.5,3)\n",
    "    NextSRE_All.append(NextSRE)\n",
    "    print('\\nThe RMSRE of Next in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSRENext) + '\\n')\n",
    "print('End of treatment ' + str(Treatments[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print errors:\n",
    "RMSREm = round((np.mean(mSRE_All))**0.5,3)\n",
    "RMSRENint = round((np.mean(NintSRE_All))**0.5,3)\n",
    "\n",
    "print('\\nError of m is: ' + str(RMSREm))\n",
    "print('\\nError of Nint is: ' + str(RMSRENint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.181, 0.224\n",
    "#0.181, 0.209\n",
    "#0.181, 0.207\n",
    "#0.178, 0.207\n",
    "#0.161, 0.239\n",
    "#0.154, 0.219\n",
    "# 0.159, 0.209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data error - step 1: calculte model prediction for each measurement\n",
    "\n",
    "# This cell adjusts measurment time to model durations - so that maximum biomass measurements\n",
    "# are compared to maximum biomass predictions and not to the initial stocking density (m0)\n",
    "\n",
    "\n",
    "# constrain times to end at 504 hours\n",
    "TModTemp = []\n",
    "TModAllOrg = []\n",
    "mModReducedAll, NintModReducedAll, NextModReducedAll = [],[],[]\n",
    "for i in range(len(TModAll)): # loops over 5 treatments\n",
    "    print(i)\n",
    "    for j in range(len(TModAll[i])): # Loops over periods in each treatment\n",
    "        Ttemp = TModAll[i][j]\n",
    "        for k in Ttemp: #The model ends at 504 hours, but some measurement reach also 50 hours. This sets a 504 hour limit\n",
    "            if k > 504:\n",
    "                k = 504\n",
    "            TModTemp.append(k)\n",
    "    TModAllOrg.append(TModTemp)\n",
    "    TModTemp = []\n",
    "\n",
    "#mExpAllTimes_val_new = []\n",
    "for i in range(len(TModAll)):\n",
    "    \n",
    "    # Calculate m model predictions - if time is out of bounderies, maximal model value is chosen\n",
    "    gm = interpolate.interp1d(TModAllOrg[i], mModAll[i],kind = 'linear')\n",
    "    mModReduced = []\n",
    "    for j in mExpAllTimes_val[i]:\n",
    "        if j >= 168 and j < 180:\n",
    "            j = 167.9\n",
    "        elif j >= 336 and j < 345:\n",
    "            j = 335.9\n",
    "        elif j > 504:\n",
    "            j = 504\n",
    "        mModReduced.append(gm(j-1))\n",
    "    mModReducedAll.append(mModReduced)  \n",
    "    \n",
    "    # Calculate Nint model predictions - if time is out of bounderies, maximal model value is chosen\n",
    "    gNint = interpolate.interp1d(TModAllOrg[i], NintModAll[i],kind = 'linear')\n",
    "    NintModReduced = []\n",
    "    for j in NintExpAllTimes_val[i]:\n",
    "        if j >= 168 and j < 180:\n",
    "            j = 167.9\n",
    "        if j >= 336 and j < 345:\n",
    "            j = 335.9\n",
    "        if j > 504:\n",
    "            j = 504\n",
    "        NintModReduced.append(gNint(j-1))\n",
    "    NintModReducedAll.append(NintModReduced)\n",
    "    \n",
    "    # Calculate Next model predictions - if time is out of bounderies, maximal model value is chosen\n",
    "    gNext = interpolate.interp1d(TModAllOrg[i], NextModAll[i],kind = 'linear')    \n",
    "    NextModReduced = []\n",
    "    for j in NextExpAllTimes_val[i]:\n",
    "        if j >= 168 and j < 180:\n",
    "            j = 167.9\n",
    "        if j >= 336 and j < 345:\n",
    "            j = 335.9\n",
    "        if j > 504:\n",
    "            j = 504\n",
    "        NextModReduced.append(gNext(j-1))\n",
    "    NextModReducedAll.append(NextModReduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data error - step 2: calculte errors for each variable\n",
    "\n",
    "mSRE_All,NintSRE_All,NextSRE_All = [],[],[]\n",
    "for i in range(len(Treatments)):\n",
    "    mSRE,NintSRE,NextSRE = [],[],[]\n",
    "    \n",
    "    # Biomass\n",
    "    \n",
    "    #df2m = df2_Reduced[(np.isnan(df2_Reduced.DW) != True)&(df2_Reduced.Exp != 3)&(df2_Reduced.Exp != 4)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "    df2m = df2_val\n",
    "    print('Treatment: ' + str(Treatments[i]) + '\\n\\nm\\n')\n",
    "    print('Number of samples: ' + str(len(df2m.Sample)) + '\\n')\n",
    "    k = 0\n",
    "    for j in df2m.Sample: # loop over all samples\n",
    "        mexp = df2m.DW # measured m\n",
    "        mmod = mModReducedAll[i] # predicted m\n",
    "        mSRE.append(((mexp.iloc[k]-mmod[k])/mmod[k])**2) # Square relative error\n",
    "        print('Sample #' + str(math.floor(float(j))))\n",
    "        print('Measured biomass: ' + str(round(mexp.iloc[k],3)))\n",
    "        print('Modeled biomass: ' + str(round(float(mmod[k]),3)) + '\\n')\n",
    "        print('Relative Error: ' + str(round(float(mSRE[k]**0.5),3)) + '\\n')\n",
    "        mSRE_All.append((((mexp.iloc[k]-mmod[k])/mmod[k])**2)) # All Square Relative Errors\n",
    "        k = k + 1\n",
    "    RMSREm = round((np.mean(mSRE))**0.5,3) # Root Mean Square relative error\n",
    "    \n",
    "    print('The RMSRE of m in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSREm) + '\\n')\n",
    "    print('end of treatment ' + str(Treatments[i]) + '\\n')\n",
    "    \n",
    "    # Internal N\n",
    "    df2Nint = df2_Reduced[(np.isnan(df2_Reduced.N) != True)&(df2_Reduced.Exp != 1)&(df2_Reduced.Exp != 2)&(df2_Reduced.Exp != 5)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "\n",
    "    print('\\nNint\\n')\n",
    "    print('Number of samples: ' + str(len(df2Nint.Sample)) + '\\n')\n",
    "    k = 0\n",
    "    for j in df2Nint.Sample: # loop over all samples\n",
    "        Nintexp = df2Nint.N # measured Nint\n",
    "        Nintmod = NintModReducedAll[i] # predicted Nint\n",
    "        NintSRE.append(((Nintexp.iloc[k]-Nintmod[k])/Nintmod[k])**2) # Square relative error\n",
    "        print('Sample #' + str(math.floor(float(j))))\n",
    "        print('Measured Nint: ' + str(round(float(Nintexp.iloc[k]),3)))     \n",
    "        print('Modeled Nint: ' + str(round(float(Nintmod[k]),3)) + '\\n')        \n",
    "        NintSRE_All.append(((Nintexp.iloc[k]-Nintmod[k])/Nintmod[k])**2) # All Square Relative Errors\n",
    "        k = k + 1\n",
    "    RMSRENint = round((np.mean(NintSRE))**0.5,3) #RMSRE\n",
    "    \n",
    "    print('\\nThe RMSRE of Nint in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSRENint) + '\\n')\n",
    "    \n",
    "    # External N\n",
    "    #df2Next = df2_Reduced[(np.isnan(df2_Reduced.NH4) != True)&(df2_Reduced.Exp != 1)&(df2_Reduced.Exp != 2)&(df2_Reduced.Exp != 5)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "    #print('\\nNext\\n')\n",
    "    #print('Number of samples: ' + str(len(df2Next.Sample)) + '\\n')\n",
    "    #k = 0\n",
    "    #for j in df2Next.Sample:\n",
    "    #    Nextexp = df2Next.NH4\n",
    "    #    if Nextexp.iloc[k] < 0:\n",
    "    #        Nextexp.iloc[k] = 0\n",
    "    #    Nextmod = NextModReducedAll[i]\n",
    "    #    NextSRE.append(((Nextexp.iloc[k]-Nextmod[k])/Nextmod[k])**2)\n",
    "    #    print('Sample #' + str(math.floor(float(j))))\n",
    "    #    print('Measured Next: ' + str(round(float(Nextexp.iloc[k]),3)))     \n",
    "    #    print('Modeled Next: ' + str(round(float(Nextmod[k]),3)) + '\\n')        \n",
    "    #    k = k + 1\n",
    "    #RMSRENext = round((np.mean(NextSRE))**0.5,3)\n",
    "    #NextSRE_All.append(NextSRE)\n",
    "    #print('\\nThe RMSRE of Next in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSRENext) + '\\n')\n",
    "print('End of treatment ' + str(Treatments[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data error - step 1: calculte model prediction for each measurement\n",
    "\n",
    "# This cell adjusts measurment time to model durations - so that maximum biomass measurements\n",
    "# are compared to maximum biomass predictions and not to the initial stocking density (m0)\n",
    "\n",
    "\n",
    "# constrain times to end at 504 hours\n",
    "TModTemp = []\n",
    "TModAllOrg = []\n",
    "mModReducedAll, NintModReducedAll, NextModReducedAll = [],[],[]\n",
    "for i in range(len(TModAll)): # loops over 5 treatments\n",
    "    print(i)\n",
    "    for j in range(len(TModAll[i])): # Loops over periods in each treatment\n",
    "        Ttemp = TModAll[i][j]\n",
    "        for k in Ttemp: #The model ends at 504 hours, but some measurement reach also 50 hours. This sets a 504 hour limit\n",
    "            if k > 504:\n",
    "                k = 504\n",
    "            TModTemp.append(k)\n",
    "    TModAllOrg.append(TModTemp)\n",
    "    TModTemp = []\n",
    "\n",
    "#mExpAllTimes_cal_new = []\n",
    "for i in range(len(TModAll)):\n",
    "    \n",
    "    # Calculate m model predictions - if time is out of bounderies, maximal model value is chosen\n",
    "    gm = interpolate.interp1d(TModAllOrg[i], mModAll[i],kind = 'linear')\n",
    "    mModReduced = []\n",
    "    for j in mExpAllTimes_val[i]:\n",
    "        if j >= 168 and j < 180:\n",
    "            j = 167.9\n",
    "        elif j >= 336 and j < 345:\n",
    "            j = 335.9\n",
    "        elif j > 504:\n",
    "            j = 504\n",
    "        mModReduced.append(gm(j-1))\n",
    "    mModReducedAll.append(mModReduced)  \n",
    "    \n",
    "    # Calculate Nint model predictions - if time is out of bounderies, maximal model value is chosen\n",
    "    gNint = interpolate.interp1d(TModAllOrg[i], NintModAll[i],kind = 'linear')\n",
    "    NintModReduced = []\n",
    "    for j in NintExpAllTimes_val[i]:\n",
    "        if j >= 168 and j < 180:\n",
    "            j = 167.9\n",
    "        if j >= 336 and j < 345:\n",
    "            j = 335.9\n",
    "        if j > 504:\n",
    "            j = 504\n",
    "        NintModReduced.append(gNint(j-1))\n",
    "    NintModReducedAll.append(NintModReduced)\n",
    "    \n",
    "    # Calculate Next model predictions - if time is out of bounderies, maximal model value is chosen\n",
    "    gNext = interpolate.interp1d(TModAllOrg[i], NextModAll[i],kind = 'linear')    \n",
    "    NextModReduced = []\n",
    "    for j in NextExpAllTimes_val[i]:\n",
    "        if j >= 168 and j < 180:\n",
    "            j = 167.9\n",
    "        if j >= 336 and j < 345:\n",
    "            j = 335.9\n",
    "        if j > 504:\n",
    "            j = 504\n",
    "        NextModReduced.append(gNext(j-1))\n",
    "    NextModReducedAll.append(NextModReduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data error - step 2: calculte errors for each variable\n",
    "\n",
    "mSRE_All,NintSRE_All,NextSRE_All = [],[],[]\n",
    "for i in range(len(Treatments)):\n",
    "    mSRE,NintSRE,NextSRE = [],[],[]\n",
    "    \n",
    "    # Biomass\n",
    "    \n",
    "    df2m = df2_Reduced[(np.isnan(df2_Reduced.DW) != True)&(df2_Reduced.Exp != 3)&(df2_Reduced.Exp != 4)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "\n",
    "    print('Treatment: ' + str(Treatments[i]) + '\\n\\nm\\n')\n",
    "    print('Number of samples: ' + str(len(df2m.Sample)) + '\\n')\n",
    "    k = 0\n",
    "    for j in df2m.Sample: # loop over all samples\n",
    "        mexp = df2m.DW # measured m\n",
    "        mmod = mModReducedAll[i] # predicted m\n",
    "        mSRE.append(((mexp.iloc[k]-mmod[k])/mmod[k])**2) # Square relative error\n",
    "        print('Sample #' + str(math.floor(float(j))))\n",
    "        print('Measured biomass: ' + str(round(mexp.iloc[k],3)))\n",
    "        print('Modeled biomass: ' + str(round(float(mmod[k]),3)) + '\\n')\n",
    "        print('Relative Error: ' + str(round(float(mSRE[k]**0.5),3)) + '\\n')\n",
    "        k = k + 1\n",
    "    RMSREm = round((np.mean(mSRE))**0.5,3) # Root Mean Square relative error\n",
    "    mSRE_All.append(mSRE) # All Square Relative Errors\n",
    "    print('The RMSRE of m in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSREm) + '\\n')\n",
    "    print('end of treatment ' + str(Treatments[i]) + '\\n')\n",
    "    \n",
    "    # Internal N\n",
    "    df2Nint = df2_Reduced[(np.isnan(df2_Reduced.N) != True)&(df2_Reduced.Exp != 3)&(df2_Reduced.Exp != 4)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "\n",
    "    print('\\nNint\\n')\n",
    "    print('Number of samples: ' + str(len(df2Nint.Sample)) + '\\n')\n",
    "    k = 0\n",
    "    for j in df2Nint.Sample: # loop over all samples\n",
    "        Nintexp = df2Nint.N # measured Nint\n",
    "        Nintmod = NintModReducedAll[i] # predicted Nint\n",
    "        NintSRE.append(((Nintexp.iloc[k]-Nintmod[k])/Nintmod[k])**2) # Square relative error\n",
    "        print('Sample #' + str(math.floor(float(j))))\n",
    "        print('Measured Nint: ' + str(round(float(Nintexp.iloc[k]),3)))     \n",
    "        print('Modeled Nint: ' + str(round(float(Nintmod[k]),3)) + '\\n')        \n",
    "        k = k + 1\n",
    "    RMSRENint = round((np.mean(NintSRE))**0.5,3) #RMSRE\n",
    "    NintSRE_All.append(NintSRE) # All Square Relative Errors\n",
    "    print('\\nThe RMSRE of Nint in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSRENint) + '\\n')\n",
    "    \n",
    "    # External N\n",
    "    #df2Next = df2_Reduced[(np.isnan(df2_Reduced.NH4) != True)&(df2_Reduced.Exp != 3)&(df2_Reduced.Exp != 4)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "    #print('\\nNext\\n')\n",
    "    #print('Number of samples: ' + str(len(df2Next.Sample)) + '\\n')\n",
    "    #k = 0\n",
    "    #for j in df2Next.Sample:\n",
    "    #    Nextexp = df2Next.NH4\n",
    "    #    if Nextexp.iloc[k] < 0:\n",
    "    #        Nextexp.iloc[k] = 0\n",
    "    #    Nextmod = NextModReducedAll[i]\n",
    "    #    NextSRE.append(((Nextexp.iloc[k]-Nextmod[k])/Nextmod[k])**2)\n",
    "    #    print('Sample #' + str(math.floor(float(j))))\n",
    "    #    print('Measured Next: ' + str(round(float(Nextexp.iloc[k]),3)))     \n",
    "    #    print('Modeled Next: ' + str(round(float(Nextmod[k]),3)) + '\\n')        \n",
    "    #    k = k + 1\n",
    "    #RMSRENext = round((np.mean(NextSRE))**0.5,3)\n",
    "    #NextSRE_All.append(NextSRE)\n",
    "    #print('\\nThe RMSRE of Next in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSRENext) + '\\n')\n",
    "print('End of treatment ' + str(Treatments[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data error - step 2: calculte errors for each variable\n",
    "\n",
    "mSRE_All,NintSRE_All,NextSRE_All = [],[],[]\n",
    "for i in range(len(Treatments)):\n",
    "    mSRE,NintSRE,NextSRE = [],[],[]\n",
    "    \n",
    "    # Biomass\n",
    "    \n",
    "    df2m = df2_Reduced[(np.isnan(df2_Reduced.DW) != True)&(df2_Reduced.Exp != 3)&(df2_Reduced.Exp != 4)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "\n",
    "    print('Treatment: ' + str(Treatments[i]) + '\\n\\nm\\n')\n",
    "    print('Number of samples: ' + str(len(df2m.Sample)) + '\\n')\n",
    "    k = 0\n",
    "    for j in df2m.Sample: # loop over all samples\n",
    "        mexp = df2m.DW # measured m\n",
    "        mmod = mModReducedAll[i] # predicted m\n",
    "        mSRE.append(((mexp.iloc[k]-mmod[k])/mmod[k])**2) # Square relative error\n",
    "        print('Sample #' + str(math.floor(float(j))))\n",
    "        print('Measured biomass: ' + str(round(mexp.iloc[k],3)))\n",
    "        print('Modeled biomass: ' + str(round(float(mmod[k]),3)) + '\\n')\n",
    "        print('Relative Error: ' + str(round(float(mSRE[k]**0.5),3)) + '\\n')\n",
    "        mSRE_All.append((((mexp.iloc[k]-mmod[k])/mmod[k])**2)) # All Square Relative Errors\n",
    "        k = k + 1\n",
    "    RMSREm = round((np.mean(mSRE))**0.5,3) # Root Mean Square relative error\n",
    "    \n",
    "    print('The RMSRE of m in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSREm) + '\\n')\n",
    "    print('end of treatment ' + str(Treatments[i]) + '\\n')\n",
    "    \n",
    "    # Internal N\n",
    "    df2Nint = df2_Reduced[(np.isnan(df2_Reduced.N) != True)&(df2_Reduced.Exp != 3)&(df2_Reduced.Exp != 4)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "\n",
    "    print('\\nNint\\n')\n",
    "    print('Number of samples: ' + str(len(df2Nint.Sample)) + '\\n')\n",
    "    k = 0\n",
    "    for j in df2Nint.Sample: # loop over all samples\n",
    "        Nintexp = df2Nint.N # measured Nint\n",
    "        Nintmod = NintModReducedAll[i] # predicted Nint\n",
    "        NintSRE.append(((Nintexp.iloc[k]-Nintmod[k])/Nintmod[k])**2) # Square relative error\n",
    "        print('Sample #' + str(math.floor(float(j))))\n",
    "        print('Measured Nint: ' + str(round(float(Nintexp.iloc[k]),3)))     \n",
    "        print('Modeled Nint: ' + str(round(float(Nintmod[k]),3)) + '\\n')        \n",
    "        NintSRE_All.append(((Nintexp.iloc[k]-Nintmod[k])/Nintmod[k])**2) # All Square Relative Errors\n",
    "        k = k + 1\n",
    "    RMSRENint = round((np.mean(NintSRE))**0.5,3) #RMSRE\n",
    "    \n",
    "    print('\\nThe RMSRE of Nint in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSRENint) + '\\n')\n",
    "    \n",
    "    # External N\n",
    "    #df2Next = df2_Reduced[(np.isnan(df2_Reduced.NH4) != True)&(df2_Reduced.Exp != 3)&(df2_Reduced.Exp != 4)&(df2_Reduced.Treatment == Treatments[i])]\n",
    "    #print('\\nNext\\n')\n",
    "    #print('Number of samples: ' + str(len(df2Next.Sample)) + '\\n')\n",
    "    #k = 0\n",
    "    #for j in df2Next.Sample:\n",
    "    #    Nextexp = df2Next.NH4\n",
    "    #    if Nextexp.iloc[k] < 0:\n",
    "    #        Nextexp.iloc[k] = 0\n",
    "    #    Nextmod = NextModReducedAll[i]\n",
    "    #    NextSRE.append(((Nextexp.iloc[k]-Nextmod[k])/Nextmod[k])**2)\n",
    "    #    print('Sample #' + str(math.floor(float(j))))\n",
    "    #    print('Measured Next: ' + str(round(float(Nextexp.iloc[k]),3)))     \n",
    "    #    print('Modeled Next: ' + str(round(float(Nextmod[k]),3)) + '\\n')        \n",
    "    #    k = k + 1\n",
    "    #RMSRENext = round((np.mean(NextSRE))**0.5,3)\n",
    "    #NextSRE_All.append(NextSRE)\n",
    "    #print('\\nThe RMSRE of Next in treamtment ' + str(Treatments[i]) + ' is: ' + str(RMSRENext) + '\\n')\n",
    "print('End of treatment ' + str(Treatments[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print errors:\n",
    "RMSREm = round((np.mean(mSRE_All))**0.5,3)\n",
    "RMSRENint = round((np.mean(NintSRE_All))**0.5,3)\n",
    "\n",
    "print('\\nError of m is: ' + str(RMSREm))\n",
    "print('\\nError of Nint is: ' + str(RMSRENint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
